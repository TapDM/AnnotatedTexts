<?xml version="1.0" encoding="UTF-8"?><html xmlns="http://www.w3.org/1999/xhtml" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:protege="http://protege.stanford.edu/plugins/owl/protege#" xmlns:xsp="http://www.owl-ontologies.com/2005/08/07/xsp.owl#" xmlns:Thesaurus="http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#" xmlns:owl="http://www.w3.org/2002/07/owl#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:dublincorens="http://purl.org/dc/elements/1.1/"  version="XHTML+RDFa 1.0" ><body>Roche-Lima et al. BMC Bioinformatics 2014, 15:318 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />  RESEARCH ARTICLE                                                                                                                             Open Access <br />  <br /> Metabolic network prediction through <br /> pairwise rational kernels <br /> Abiel Roche-Lima1* , Michael Domaratzki1 Brian Fristensky2 <br />  <br />  <br />   <span id='am-1' about='protege:abstract' typeof='owl:Thing'>Abstract</span> <br />   Background: Metabolic networks represented set metabolic pathways. Metabolic pathways series <br />   biochemical reactions, product (output) reaction serves substrate (input) another <br />   reaction. Many pathways remain incompletely characterized. One major challenges computational biology is <br />   obtain better models metabolic pathways. Existing models dependent annotation genes. This <br />   propagates error accumulation pathways predicted incorrectly annotated genes. Pairwise <br />   classification methods supervised learning methods used classify new pair entities. Some these <br />   classification methods, e.g., Pairwise Support Vector Machines (SVMs), use pairwise kernels. Pairwise kernels describe <br />   similarity measures pairs entities. Using pairwise kernels handle sequence data requires long <br />   processing times large storage. Rational kernels kernels based weighted finite-state transducers that <br />   represent similarity measures sequences automata. They effectively used problems that <br />   handle large sequence information protein essentiality, natural language processing machine <br />   translations. <br />   Results: We create new family pairwise kernels using weighted finite-state transducers (called Pairwise Rational <br />   Kernel (PRK)) predict metabolic pathways variety biological data. PRKs advantage simpler <br />   representations faster algorithms transducers. Because raw sequence data used, predictor model <br />   avoids errors introduced incorrect gene annotations. We developed experiments PRKs and <br />   Pairwise SVM validate methods using metabolic network Saccharomyces cerevisiae. As result, PRKs <br />   used, method executes faster comparison pairwise kernels. Also, use PRKs combined <br />   simple kernels include evolutionary information, accuracy values improved, while <br />   maintaining lower construction execution times. <br />   Conclusions: The power using kernels sort data represented using kernels. Therefore, <br />   completely disparate types data combined add power kernel-based machine learning methods. When <br />   compared proposal using PRKs similar kernel, execution times decreased, no <br />   compromise accuracy. We proved combining PRKs kernels include evolutionary <br />   information, accuracy also improved. As proposal use type sequence data, genes do <br />   need properly annotated, avoiding accumulation errors incorrect previous annotations. <br />   Keywords: Metabolic network, Pairwise rational kernels, Supervised network inference, Finite-state transducers, <br />   Pairwise support vector machine <br />  <br />  <br />  <br />  <br /> *Correspondence: aroche@cs.umanitoba.ca <br /> 1 Department Computer Science, University Manitoba, Winnipeg, <br /> Manitoba, Canada <br /> Full list author information available end article <br />  <br />  <br />                                          &#194;&#169; 2014 Roche-Lima et al.; licensee BioMed Central Ltd. This Open Access article distributed terms Creative <br />                                          Commons Attribution License (http://creativecommons.org/licenses/by/4.0), permits unrestricted use, distribution, and <br />                                          reproduction medium, provided original work properly credited. The Creative Commons Public Domain Dedication <br />                                          waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies data available article, unless otherwise <br />                                          stated. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                               Page 2 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Background                                                       Yamanishi [9] Kotera et al. [11] described the <br /> Related work                                                   theory implementation GENIES, web applica- <br /> Metabolic networks allow modelling molecular sys-       tion allowed prediction unknown parts of <br /> tems understand underlying biological mechanisms        metabolic networks using supervised graph inference and <br /> in cell [1]. Metabolic networks represented set   kernel methods. Several algorithms implemented <br /> of metabolic pathways. Metabolic pathways series      GENIES decision predictive func- <br /> biochemical reactions, product (output)      tions supervised network inference. Some these <br /> one reaction serves substrate (input)        algorithms Kernel Canonical Correlation Analysis <br /> reaction. The experimental determination metabolic          (KCCA) [13,14], Expectation-Maximization (EM) algo- <br /> networks, based known biological data DNA           rithm [15] Kernel Matrix Regression (KMR) [9]. The <br /> or protein sequences, gene expression data,   authors developed experiments, did not <br /> challenging [2]. Thus, efforts      use sequence data. Therefore, motivations <span id='am-8' about='protege:TO' typeof='owl:Thing'>to</span> <br /> develop supervised learning methods determine genes         extend previous research [7] use sequence <br /> coding missing enzymes predict unknown parts        data combined algorithms. As noted above, we <br /> metabolic networks [3,4].                                      obtained best accuracy values SVM method <br />   Most methods predict metabolic networks            combined sequence kernels, high execution <br /> assume genome annotation correct, e.g., Path-      times. <br /> way Tools [4], software application predict metabolic       To address high computational costs, con- <br /> networks using information BioCyc databases [5].          sider results Allauzen et al. [16], proposed <br /> Pathway Tools uses algorithm,         method predict protein essentiality using SVMs and <br /> 1 infers reactions catalyzed organism          manipulating sequence data using rational kernels. The <br /> the set enzymes present annotated genome,            authors designed sequence kernels (called general <br /> and 2 infers metabolic pathways present        domain-based kernels), instances rational <br /> organism reactions 1. Con-          kernels. To handle large data (6190 domains <br /> sidering BioCyc MetaCyc huge              3000 protein sequences), automata rep- <br /> available data, application potentially make pre-     resentation used create rational kernels. Their <br /> cise metabolic pathway predictions [6]. However,          results showed final kernels favourably predicted <br /> 2 based annotated genes,            protein essentiality. We note, however, the <br /> errors annotation, inferred pathways           previous works using rational kernels bioinformatics <br /> not correct. Therefore, methods intrinsically         [16-18] considered problems related biological <br /> carry error accumulations incorrect genome              network predictions. <br /> annotations.                                                     Based fact rational kernels described by <br />   To tackle problem, previously proposed          Allauzen et al. [16] extended problems, <br /> using information directly related sequence          define new kernels applied metabolic network <br /> the primary data (e.g., genomic proteomic data)            predictions. In research, represent sequence data <br /> [7]. As result, obtained best accuracy values         using rational kernels. Rational kernels advantage of <br /> using Support Vector Machine (SVM) methods combined            fast algorithms for, efficient representation of, <br /> with <span id='am-2' about='xsd:string' typeof='owl:Thing'>string</span> kernels representing sequence data. We         transducers sequence manipulations improve per- <br /> experimentally demonstrated SVMs supersede          formance. As sequence data used, raw genomic <br /> methods, matrix kernel regression, predict-        proteomic information considered, this <br /> ing metabolic networks. This consistent recent         method avoids problems associated incorrect anno- <br /> results showing usefulness SVMs bioinformatics       tation predicting metabolic networks. Additionally, <br /> [8]. However, solution [7] computationally expen-      current work combine rational kernels <br /> sive terms execution time sequence data       (using finite-state transducers) [17-20] known pair- <br /> manipulation.                                                  wise kernels [10,21-23] obtain pairwise rational kernels. <br />   Other authors combined SVM               While kernel techniques proposed paper can <br /> supervised learning techniques kernel methods          applied equally machine learning tools that <br /> predict metabolic networks [9-11]. The main advantage          employ kernel methods, KCCA, EM KMR, we <br /> of using kernel methods heterogeneous data         focused SVMs illustration capabil- <br /> be represented combined simultaneously. Thus,           ity reduce computational costs. We chosen <br /> disparate types data manipulated kernels,         SVM methods light experimental results we <br /> data sources contribute uni-          obtained previous works [7], efficiency <br /> formly information training set building    effectiveness SVM methods predict protein <br /> model [12].                                                    essentiality [16]. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                      Page 3 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Automata transducers                                             As example, weighted transducer shown in <br /> Automata define mathematical formalism analyze            Figure 1(a). We use delimiters colon sepa- <br /> model real problems useful machines [24]. An               rate input output labels transitions and <br /> automaton set states (generally represented            slash separate weight values (i.e., nota- <br /> circles), transitions (generally represented arrows).       tion input:output/weight). States represented by <br /> The automaton moves state state                circles, set initial states bold circles and <br /> (makes transition) activated event func-           set final states double circles. Only ini- <br /> tion. One variant automaton called finite state           tial final states associated weighs (the notation <br /> machine. A finite-state machine used model               state/weight). Example 1 shows compute the <br /> a simple system, turnstiles transit lights,          weight transducer T (i.e., T(x, y)) given <br /> complex systems sophisticated spaceship controls           sequences x y. In case, define alphabets <br /> [25].                                                                = {G, C}   = {G, C}. <br />    Automata work sequence symbols,   &#226;&#710;&#8212; <br /> denotes finite sequences using symbols          Example 1. The weight (or value) associated trans- <br /> alphabet  , including   represents sym-             ducer T Figure 1(a) pair (x, y) = (GGC, CCG) &#226;&#710;&#710; <br /> bol. In order formally define automata transducers,           &#226;&#710;&#8212; &#195;&#8212;  &#226;&#710;&#8212; computed as: <br /> we follow notations used Cortes et al. [17]. An             T(GGC, CCG) = 1 &#226;&#710;&#8212; 2 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 6 &#226;&#710;&#8212; 1 + 1 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 1 &#226;&#710;&#8212; 4 &#226;&#710;&#8212; 1 = 48, <br /> automaton A 5-tuple ( , Q, I, F, &#206;&#180;) [24]         considering accepting paths labelled <br /> input alphabet set, Q state set, I &#226;&#352;&#8218; Q subset        input GCC output CCG. These paths are: <br /> of initial states, F &#226;&#352;&#8218; Q subset final states,             Path 1 : State 0   &#226;&#8224;&#8217; State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 3, <br /> &#206;&#180; &#226;&#352;&#8224; Q &#195;&#8212; (  &#226;&#710;&#170; { }) &#195;&#8212; Q transition set. A transition               Path 2 : State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 2   &#226;&#8224;&#8217; State 3. <br /> &#206;&#185; &#226;&#710;&#710; &#206;&#180; describes actions moving state            The initial final values terms T(GGC, CCG) <br /> another condition (input symbol) encountered.            correspond weights initial final <br />    Similarly, Finite-State Transducer (FST) automa-        states. <br /> ton output <span id='am-6' about='rdfs:label' typeof='owl:Thing'>label</span> included transition in <br /> addition input label. Based <span id='am-4' about='Thesaurus:DEFINITION' typeof='owl:Thing'>definition</span>,          Figure 1(b) shows graph representation weighted <br /> a FST T 6-tuple ( ,  , Q, I, F, &#206;&#180;) [18], new        automaton. It obtained output projection of <br /> term   output alphabet transition set &#206;&#180;          transducer T input labels omitted. Thus, <br /> now &#206;&#180; &#226;&#352;&#8224; Q &#195;&#8212; (  &#226;&#710;&#170; { }) &#195;&#8212; (  &#226;&#710;&#170; { }) &#195;&#8212; Q. Similar pre-         alphabet     = {G, C} weight computation <br /> vious <span id='am-5' about='Thesaurus:DEFINITION' typeof='owl:Thing'>definition</span>, transition &#206;&#185; &#226;&#710;&#710; &#206;&#180; action moving       automaton A given sequences shown in <br /> <span id='am-3' about='protege:FROM' typeof='owl:Thing'>from</span> state input symbol               Example 2. <br /> is encountered output   produced. <br />    In addition, Automata Finite-State Transducers          Example 2. The weight (or value) associated the <br /> be weighted, transition labelled              Automaton A Figure 1(b) y = CCG &#226;&#710;&#710;  &#226;&#710;&#8212; com- <br /> weight. Thus, Weighted Automaton (WA) 7-tuple               puted as: <br /> ( , Q, I, F, &#206;&#180;, &#206;&#187;, &#207;?) Weighted Finite-State Transducer            A(CCG) = 1 &#226;&#710;&#8212; 2 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 6 &#226;&#710;&#8212; 1 + 1 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 1 &#226;&#710;&#8212; 4 &#226;&#710;&#8212; 1 = 48 <br /> (WFST) 8-tuple ( ,  , Q, I, F, &#206;&#180;, &#206;&#187;, &#207;?) [18],       considering accepting paths labelled <br /> new terms &#206;&#187; &#207;? are: &#206;&#187; : I &#226;&#8224;&#8217; R, initial weight func-         CCG. These paths are: <br /> tion, &#207;? : F &#226;&#8224;&#8217; R, final weight function. The new                 Path 1 : State 0   &#226;&#8224;&#8217; State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 3, <br /> transitions WAs WFSTs &#206;&#180; &#226;&#352;&#8224; Q&#195;&#8212;( &#226;&#710;&#170;{ })&#195;&#8212;                    Path 2 : State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 2   &#226;&#8224;&#8217; State 3. <br /> R&#195;&#8212;Q &#206;&#180; &#226;&#352;&#8224; Q&#195;&#8212;( &#226;&#710;&#170;{ })&#195;&#8212;( &#226;&#710;&#170;{ })&#195;&#8212;R&#195;&#8212;Q, respectively,                   The initial final values terms A(CCG) <br /> where R represents weights real numbers.                    correspond weights initial final states. <br />  <br />  <br />  <br />  <br />  Figure 1 Weighted transducer weighted automaton representing sequences alphabet   =   = {G, C}. (a) Weighted <br />  Transducer T. (b) Weighted Automaton A (A obtained projecting output T). <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                      Page 4 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />   There operations defined automata                 Using Algorithm 1, overall complexity com- <br /> transducers, inverse composition. Given             pute value rational kernel O(|U||Mx ||My |), <br /> transducer T, inverse T &#226;&#710;&#8217;1 transducer obtained           |U| remains constant. In practice, complexity is <br /> when input output labels swapped               reduced O(|U| + |Mx | + |My |) kernels which <br /> transition. The composition operation transduc-              used areas natural language process- <br /> ers T1 T2 input output alphabets                  ing computational biology. For example, Algorithm 1 <br /> equal   weighted transducer, denoted T1 &#226;&#8212;&#166;                n-gram kernel linear complexity (see a <br />  2 , provided sum given (T1 &#226;&#8212;&#166; T2 )(x, y) = <br /> T                                                                   detailed description n-gram kernel below). <br />    z&#226;&#710;&#710;  &#226;&#710;&#8212; T1 (x, z)T2 (z, y) defined R (x, y) &#226;&#710;&#710;      Kernels used training methods discriminant clas- <br />  &#226;&#710;&#8212;.                                                                 sification algorithms (e.g., SVM) need satisfy Mercer&#226;&#8364;&#8482;s <br />                                                                     condition equivalently Positive Definite Sym- <br /> Rational kernels                                                    metric - PDS [18]. Cortes et al. [18] proven result <br /> In order manipulate sequence data, FSTs provide sim-           gives general method construct PDS rational <br /> ple representation efficient algorithms          kernel using WFSTs. <br /> composition shortest-distance [18]. Rational Kernels, <br /> based Finite-State Transducers, effective ana-           Theorem 1. ([18]). If T arbitrary weighted trans- <br /> lyzing sequences variable lengths [17].                        ducer, U = T &#226;&#8212;&#166; T &#226;&#710;&#8217;1 defines PDS rational kernel. <br />   As formal <span id='am-9' about='Thesaurus:DEFINITION' typeof='owl:Thing'>definition</span>, function k :   &#226;&#710;&#8212; &#195;&#8212;  &#226;&#710;&#8212; &#226;&#8224;&#8217; R <br /> is rational kernel exists WFST U k           n-gram kernel rational kernel <br /> coincides function defined U, i.e., k(x, y) =           Hofmann et al. [26] defined class similarity mea- <br /> U(x, y) sequences x, y &#226;&#710;&#710;   &#226;&#710;&#8212; &#195;&#8212;  &#226;&#710;&#8212; [17]. From            sures biological sequences function of <br /> on, consider input output alphabets             number equal subsequences have. As an <br /> same symbols (i.e.,   =  ), terms     &#226;&#710;&#8212;            example measures spectrum kernel defined <br /> will used.                                                       Leslie et al. [27]. Similarity values results of <br />   In order compute value U(x, y) partic-            summing products counts sub- <br /> ular pair sequences x, y &#226;&#710;&#710;   &#226;&#710;&#8212; &#195;&#8212;   &#226;&#710;&#8212; , composition           sequences. It referred computational biology <br /> algorithm weighted transducers used [17]:                     k-mer n-gram kernel. In rest paper, we <br />                                                                     use term n-gram follow notation Hofmann <br />   &#226;&#8364;&#162; First, Mx , My considered trivial weighted <br />                                                                     et al. [26] Cortes et al. [17]. <br />     transducers representing x, y respectively, where <br />     Mx (x, x) = 1 Mx (v, w) = 0 v  <br />  = x w  <br />  = x.          The n-gram kernel defined kn (x, y)                  = <br />                                                                        |z|=n cx (z)cy (z) fixed integer n, represents <br />     Mx obtained using linear finite automata <br />                                                                     subsequences <span id='am-7' about='xsp:length' typeof='owl:Thing'>length</span> n. Here, ca (b) number of <br />     representing x augmenting transition an <br />                                                                     times subsequence b appears a. kn be <br />     output label identical input label setting <br />                                                                     represented rational kernel using weighted trans- <br />     transition, initial final weights one. My is <br />                                                                     ducer Un = Tn &#226;&#8212;&#166; Tn&#226;&#710;&#8217;1 , transducer Tn defined <br />     obtained similar way using y. <br />                                                                     Tn (x, z) = cx (z), x, z &#226;&#710;&#710;     &#226;&#710;&#8212; |z| = n [18]. <br />   &#226;&#8364;&#162; Then, <span id='am-10' about='Thesaurus:DEFINITION' typeof='owl:Thing'>definition</span> weighted transducer <br />                                                                     For example, n = 2, k2 (x, y) = |z|=2 cx (z)cy (z) the <br />     composition: <br />                                                                     rational kernel z represents subsequences <br />     (Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; My )(x, y) = Mx (x, x)U(x, y)My (y, y). <br />                                                                       &#226;&#710;&#8212; size 2 T2 (x, z) = cx (z) counts many <br />     Considering Mx (x, x) = 1 My (y, y) = 1, we <br />                                                                     times z occurs x. <br />     obtain (Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; My )(x, y) = k(x, y), i.e., sum of <br />                                                                       Allauzen et al. [16] extended construction of <br />     weights paths Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; My exactly <br />                                                                     kernel, kn , measure similarity between <br />     U(x, y) = k(x, y). <br />                                                                     sequences represented automata. Firstly, define <br />   Based representation, two-step algorithm             count      sequence z weighted automaton A <br /> defined Cortes et al. [17] obtain k(x, y) = U(x, y).          cA (z) =         u&#226;&#710;&#710;  &#226;&#710;&#8212; cu (z)A(u), u ranges the <br />                                                                     set sequences   &#226;&#710;&#8212; represented by <br />                                                                     automaton A. This equation represents sums <br />                                                                     obtained u, times z occurs in <br /> Algorithm 1 Rational Kernel Computation                             u multiplied weight (or value) associated the <br /> INPUT: pair sequences (x, y) WFST U                        sequence u automaton A (as computed in <br /> (i) compute N using composition N = Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; My                  Example 2). <br /> (ii) compute sum paths N using                          Then, similarity measure weighted <br /> shortest-distance algorithm, equal U(x, y).             automata A1 A2 , according n-gram kernel kn , is <br /> RESULTS: value k(x, y) = U(x, y)                                 defined as: <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                           Page 5 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />                         <br />     kn (A1 , A2 ) =           (A1 &#226;&#8212;&#166; Tn &#226;&#8212;&#166; Tn&#226;&#710;&#8217;1 &#226;&#8212;&#166; A2 )(x, y)             di binary values (e.g., pair (xi , yj ) classified as <br />                       x,y&#226;&#710;&#710;X                                            +1 &#226;&#710;&#8217;1), = 1, . . . , n, j = 1, . . . , n mapping <br />                                                                        function 	, Pairwise SVM methods opti- <br />                  =            cA1 (z)cA2 (z)                    (1) <br />                                                                        mal hyperplane, wT 	(xi , yi ) + b = 0, separate the <br />                       |z|=n <br />                                                                        points categories. One solutions based on <br />   Based definition using Algorithm 1,                  dual formalism optimization problem described <br /> n-gram rational kernel constructed time                      Cortes et al. [33]. In case decision function is: <br /> O(|Un | + |Mx | + |My |), described Allauzen et al. [16]                           n                              <br /> and Mohri et al. [28].                                                       f (x, y) =       &#206;&#177;ij K (xi , yj ), (x, y) + b, <br />                                                                                             i,j <br />   Yu et al. [29] verified n-gram sequence kernels <br /> alone good predict protein interactions. <br /> We address concerns experiments combin-                K pairwise kernel, (xi , yj ) set train- <br /> ing n-gram kernels include evolutionary                ing examples, &#206;&#177; obtained Lagrange Multipliers <br /> information.                                                           function w (the normal vector) b offset <br />                                                                        hyperplane (please, Cortes et al. [33] more <br /> Pairwise kernels <br />                                                                        details). In case, &#206;&#177; b &#226;&#8364;&#339;learned&#226;&#8364;? parame- <br /> We apply kernel methods problem predicting <br />                                                                        ters training process. Thus, f classifies new <br /> relationships given entities, i.e., pairwise pre- <br />                                                                        pairs (x, y). For example, f (x, y) &gt;= 0, (x, y) classified <br /> diction. Models solve problem input <br />                                                                        +1, (x, y) classified &#226;&#710;&#8217;1. <br /> two instances, output relationship between <br /> them. Kernels used models need define simi-                Metabolic networks <br /> larities arbitrary pairs entities. Typically,           In work, metabolic network represented a <br /> the construction pairwise kernels K based simple             graph, vertices enzymes, the <br /> kernels k, k : X &#195;&#8212; X &#226;&#8224;&#8217; R. In paper differ-             edges enzyme-enzyme relations (two proteins are <br /> ent pairwise kernels investigated: Direct Sum Learning             enzymes catalyze successive reactions known path- <br /> Pairwise Kernel [21], Tensor Learning Pairwise Kernel (or              ways). Figure 2 represents graphical transition a <br /> Kronecker Kernel) [22,30,31], Metric Learning Pairwise                 metabolic pathway graph. <br /> Kernel [23] Cartesian Pairwise Kernel [10].                           In traditional representation metabolic path- <br />   All pairwise functions guarantee symmetry                  way, enzymes vertices (nodes), metabolites are <br /> of pairwise kernels K, i.e., K((x1 , y1 ), (x2 , y2 )) =           edges (branches). Following Yamanishi [9], represent <br /> K((x2 , y2 ), (x1 , y1 )), x1 , x2 , y1 , y2 &#226;&#710;&#710; X. Also,   differently, interactions pairs of <br /> simple kernel k PDS (satisfies Mercer condition),               enzymes considered discrete data points. For exam- <br /> the resulting pairwise kernel K PDS,               ple, Figure 2(a), enzyme numbered EC 5.3.1.9 <br /> the pairwise kernels defined [10,32].                            create D-fructose-6-phosphate product, which <br />                                                                        turn used substrate enzyme numbered <br /> Pairwise support vector machine <br />                                                                        EC 2.7.1.11. This means enzyme-enzyme rela- <br /> The rationale preceding discussion represent- <br />                                                                        tion EC 5.3.1.9 EC 2.7.1.11. Then, create <br /> ing disparate types data kernels enable to <br />                                                                        graph enzyme-enzyme relations edges <br /> use machine learning formalisms Support <br />                                                                        enzymes nodes shown Figure 2(b). If there <br /> Vector Machines (SVMs). SVMs used classifica- <br />                                                                        relation enzymes, relation clas- <br /> tion regression analysis, defined supervised models <br />                                                                        sified +1 (i.e., interacting pair). Enzyme-enzyme pairs <br /> with associated learning algorithms [33]. In research, <br />                                                                        relation exists classified &#226;&#710;&#8217;1 (non- <br /> we use SVMs classification. SVMs represents data <br />                                                                        interacting pairs). Figure 2(c) describes classifica- <br /> as vectors vector space (i.e., input feature space). <br />                                                                        tions, used training set SVM method. <br /> As training set, entities xi (vectors) classified <br /> in categories given. A SVM trained                Using pairwise kernel SVM predict metabolic <br /> hyperplane separates vector space parts.               networks <br /> Each feature space groups entities                The input data, considered training example <br /> the category. Then, new entity x classified              dataset ((xi , yi ), di ), set known pairs enzymes <br /> depending location feature space related           (or genes) classified categories (interacting or <br /> hyperplane [33].                                                       non-interacting pairs). Figure 3(a) shows example of <br />   Pairwise Support Vector Machines, instead, classify pair             input data, obtained metabolic network <br /> of entities (x, y) [32]. Let formally define binary             described Figure 2(c). In Figure 3(a), enzymes rep- <br /> Pairwise Support Vector Machine formulation, following                 resented EC number (top) gene nomenclature <br /> Brunner et al. [32]: given training data ((xi , yj ), di ),    (bottom). <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                                    Page 6 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />  Figure 2 Conversion metabolic network graph representation. (a) Part Glycolysis Pathways, BioCyc Database [5,6]. <br />  (b) The resulting graph nodes (enzymes) edges (enzyme-enzyme relations). (c) Table represents known enzymes relations (EC <br />  numbers related classified +1 non-related -1). <br />  <br />  <br />   Figure 3(b) represents example pairwise                         A Pairwise SVM based dual formalism the <br /> kernel (K((x1 , y1 ), (x2 , y2 ))). Several state-of-the-art pair-        optimization problem represented Figure 3(c). The <br /> wise kernels mentioned above. For example,                     parameters &#206;&#177;ij b learned, using pairwise <br /> consider Tensor Product Pairwise Kernel K [22],                  kernel, K, training dataset, (xi , yi ). Finally, new <br /> K((x1 , y1 ), (x2 , y2 )) computed using simple kernel k             pairs enzymes genes (x, y) classified as <br /> (e.g., k simple Phylogenetic (PFAM) ker-                     interacting not-interacting, depending evaluation <br /> nel described Ben-Hur et al. [22]). The PFAM kernel                    decision function f (see example representation <br /> (kpfam (x, y)) describes similarity measures based                 Figure 3(d)). By predicting gene interactions the <br /> PFAM database [34] gene x gene y.                     unseen examples, metabolic pathways be <br /> Thus, Tensor Product Pairwise Kernel K, using                    predicted. <br /> simple kernel PFAM Kernel kpfam defined as:                          The pairwise kernel computation most <br />     K((x1 , y1 ), (x2 , y2 )) = kpfam (x1 , x2 ) &#226;&#710;&#8212; kpfam (y1 , y2 )       expensive tasks prediction metabolic <br />                                                                           networks processing storage. Using sequence data <br />                                 + kpfam (x1 , y2 ) &#226;&#710;&#8212; kpfam (y1 , x2 )     causes longer execution times large storage <br />   For example, Figure 3(b)-bottom, genes                    needs. However, mentioned advantages of <br /> associated variables follow: x1 = YAR071W, y1 =                 using sequence data order avoid error accumu- <br /> YAL002W, x2 = YDR127W, y2 = YAL038W, Tensor                           lation genome annotation dependencies. As <br /> Product Pairwise Kernel is:                                               well, SVMs guarantee better accuracy values other <br />  <br />     K ((x1 , y1 ), (x2 , y2 )) = kpfam (YAR071W, YDR127W) &#226;&#710;&#8212; kpfam (YAL002W, YAL038W) <br />                  + kpfam (YAR071W, YAL038W) &#226;&#710;&#8212; kpfam (YAL002W, YDR127W) = 0.5. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                                              Page 7 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />  Figure 3 Diagram pairwise SVM applied metabolic network prediction. (a) An example pairs training set using EC <br />  numbers (top) gene names (bottom). (b) The pairwise kernel matrix, numerical values cell correspond measure of <br />  similarities, given pairs EC numbers (top) pairs gene names (bottom). (c) A model trained estimate parameters &#206;&#177;i,j b of <br />  decision function f . (d) Given new pair EC numbers (left) gene names (right) decision function evaluated pair classified as <br />  interacting non-interacting. <br />  <br />  <br />  <br />  <br /> supervised learning methods sequence ker-                              &#226;&#8364;&#162; Tensor Product Pairwise Rational Kernel <br /> nels metabolic network inference [7]. Therefore,                             (KPRKT ) if <br /> focus improvement pairwise kernel computa-                                K((x1 , y1 ), (x2 , y2 )) = U(x1 , x2 ) &#226;&#710;&#8212; U(y1 , y2 )+ <br /> tions representation, incorporating rational kernels                         U(x1 , y2 ) &#226;&#710;&#8212; U(y1 , x2 ) <br /> to manipulate sequence data. To accomplish this,                           &#226;&#8364;&#162; Metric Learning Pairwise Rational Kernel <br /> have proposed new framework called Pairwise Rational                              (KPRKM ) if <br /> Kernels.                                                                            K((x1 , y1 ),(x2 , y2 )) = (U(x1 , x2 )&#226;&#710;&#8217;U(x1 , y2 )&#226;&#710;&#8217;U(y1 , x2 ) <br />                                                                                                               +U(y1 , y2 ))2 <br /> Methods                                                                           &#226;&#8364;&#162; Cartesian Pairwise Rational Kernel (KPRKC ) if <br /> Pairwise rational kernels <br />                                                                                     K((x1 , y1 ), (x2 , y2 )) = U(x1 , x2 ) &#226;&#710;&#8212; &#206;&#180;(y1 = y2 ) <br /> In section, propose new pairwise kernels based <br />                                                                                                                 +&#206;&#180;(x1 = x2 ) &#226;&#710;&#8212; U(y1 , y2 ) <br /> on rational kernels, i.e., Pairwise Rational Kernels (PRKs). <br />                                                                                                                 +U(x1 , y2 ) &#226;&#710;&#8212; &#206;&#180;(y1 = x2 ) <br /> They obtained using rational kernels sim- <br />                                                                                                                 +&#206;&#180;(x1 = y2 ) &#226;&#710;&#8212; U(y1 , x2 ) <br /> ple kernels k. We defined PRKs, based on <br />                                                                                     &#206;&#180;(x = y) = 1 x = y 0 otherwise, <br /> the notations definitions Background Section <br />                                                                                     &#226;&#710;&#8364;x, y &#226;&#710;&#710; X. <br /> above. <br /> Definition 1. Given X &#226;&#352;&#8224;   &#226;&#710;&#8212; transducer U,                            Following Theorem 1, construct U using a <br /> function                                                                        weighted transducer T, U = T &#226;&#8212;&#166; T &#226;&#710;&#8217;1 , then <br /> K : (X &#195;&#8212; X) &#195;&#8212; (X &#195;&#8212; X) &#226;&#8224;&#8217; R is:                                                   guarantee U Positive Definite Symmetric <br />                                                                                 (PDS) kernel. PDS needed condition use kernels <br />   &#226;&#8364;&#162; Direct Sum Pairwise Rational Kernel (KPRKDS )                          training classification algorithms. Since kernels <br />     K((x1 , y1 ), (x2 , y2 )) = U(x1 , x2 ) + U(y1 , y2 )+                      defined results PDS kernel operations, the <br />     U(y1 , x2 ) + U(x1 , y2 )                                                   PRK kernels PDS [35]. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                      Page 8 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Algorithm                                                          graph species. As used SVM methods for <br /> We designed general algorithm, Algorithm 2,              metabolic network inference, prefer balanced <br /> compute kernels, using composition weighted             dataset. In dataset, unbalanced pro- <br /> transducers. This extension Algorithm 1. It             portions interacting (+1) non-interacting (&#226;&#710;&#8217;1) <br /> uses input transducers Mx1 , My1 , Mx2 , My2 ,           classified pairs (e.g., dataset 282060 <br /> that represent sequences x1 , y1 , x2 , y2 &#226;&#710;&#710; X         non-interacting pairs). In order balance dataset, we <br /> Weighted Finite-State Transducer U, outputs                followed procedure recommended Yu et al. [29], <br /> value K((x1 , y1 ), (x2 , y2 )).                                using program BRS-noint select non-interacting <br />                                                                    pairs. Yu et al. [29] describes bias non- <br /> Algorithm 2 Pairwise Rational Kernel Computation                   interacting pair selection training process and <br />                                                                    accuracy estimation. To eliminate bias, BRS- <br /> INPUT: pairs sequences (x1 , y1 ), (x2 , y2 ) WFST U <br />                                                                    noint program used create &#226;&#8364;&#339;balanced&#226;&#8364;? negative <br /> (i) obtain Mx1 , My1 , Mx2 , My2 use transducer <br />                                                                    set maintain right distribution non-interacting <br /> composition compute: <br />                                                                    interacting pairs. As result, obtained 2574 non- <br /> N1 = Mx1 &#226;&#8212;&#166; U &#226;&#8212;&#166; Mx2 <br />                                                                    interacting pairs total 5149 pairs training <br /> N2 = Mx1 &#226;&#8212;&#166; U &#226;&#8212;&#166; My2 <br />                                                                    process. <br /> N3 = My1 &#226;&#8212;&#166; U &#226;&#8212;&#166; Mx2 <br /> N4 = My1 &#226;&#8212;&#166; U &#226;&#8212;&#166; My2 <br /> (ii) compute sum paths N1 , N2 , N3 , N4 using       Training process kernel computation <br /> shortest-distance algorithm                                        The known metabolic network converted <br /> (iii) compute formulas Definition 1:                        graph obtained pairs training set, <br /> KPRKDS ((x1 , y1 ), (x2 , y2 )) = N1 + N2 + N3 + N4                corresponding Figure 3(a). The PRK representation <br /> KPRKT ((x1 , y1 ), (x2 , y2 )) = N1 &#226;&#710;&#8212; N4 + N2 &#226;&#710;&#8212; N3                 coincides Figure 3. Here, compu- <br /> KPRKM ((x1 , y1 ), (x2 , y2 )) = (N1 &#226;&#710;&#8217; N2 &#226;&#710;&#8217; N3 + N4 )2             tation PRKs (which main contribution this <br /> KPRKC ((x1 , y1 ), (x2 , y2 )) = N1 &#226;&#710;&#8212;&#206;&#180;(y1 = y2 )+N2 &#226;&#710;&#8212;&#206;&#180;(y1 = x2 )   research), given data yeast Saccharomyces <br /> +N3 &#226;&#710;&#8212; &#206;&#180;(x1 = y2 ) + N4 &#226;&#710;&#8212; &#206;&#180;(x1 = x2 )                               cerevisiae: <br /> RESULTS: values K((x1 , y1 ), (x2 , y2 )) <br />                                                                      &#226;&#8364;&#162; 755 known genes represented a <br />                                                                        trivial weighted automaton (i.e., Ax1 , Ax2 , . . . Ax755 ) <br />   In implementation described below, use n-                 using nucleotide sequences, <br /> gram rational kernel kernel U (see n-gram kernel          &#226;&#8364;&#162; n-gram kernel, n = 3, used rational <br />                                                                                                           <br /> as rational kernel Section details). Then,              kernel, U(Ax1 , Ax2 ) = |z|=3 cAx1 (z)cAx2 (z) (see <br /> complexity steps (i) (ii) O(|Mx1 | + |My1 | +               n-gram kernel rational kernel Section for <br /> |Mx2 | + |My2 |). Step (iii) adds constant time complexity.          details), <br /> We conclude PRKs  based n-gram kernels              &#226;&#8364;&#162; Algorithm 2 implemented obtain K values, <br /> be computed time O |Mx1 | + |My1 | + |Mx2 | + |My2 | .            &#226;&#8364;&#162; example, Tensor Product Pairwise Rational <br />                                                                        Kernel Definition 1 obtained by: <br /> Experiments <br />                                                                        KPRKT ((x1 , y1 ), (x2 , y2 )) = <br /> In section experiments predict <br /> metabolic networks using pairwise SVMs combined                   = U(Ax1 , Ax2 ) &#226;&#710;&#8212; U(Ay1 , Ay2 ) + U(Ax1 , Ay2 ) <br /> PRKs. We aim prove advantage using PRKs                      +U(Ay1 , Ax2 ) <br />                                                                                                          <br /> improve execution time computation                   = |z|=3 cAx1 (z)cAx2 (z) &#226;&#710;&#8212; |z|=3 cAy1 (z)cAy2 (z)+ <br />                                                                                                           <br /> pairwise kernels training process, maintain-                + |z|=3 cAx1 (z)cAy2 (z) &#226;&#710;&#8212; |z|=3 cAy1 (z)cAx2 (z). <br /> ing improving accuracy values. <br />                                                                      &#226;&#8364;&#162; finally, PRK kernels K positive <br /> Dataset                                                                eigenvalues normalized avoid fact that <br /> We used data yeast Saccharomyces cerevisiae                   longer sequences contain n-grams, <br /> [36]. This species selected compare methods,                resulting similarities [16]. <br /> implementations results methods also <br /> predict biological networks Saccharomyces cerevisiae             We implemented method compute PRKs <br /> [9,10,22].                                                         using Open Finite-State Transducer (OpenFST) library <br />   The data species taken KEGG               [38] OpenKernel library [39]. The input data were <br /> pathway [37] converted graph described                 nucleotide sequences known genes, outputs <br /> in previous section (see Figure 2 details).           pairwise rational kernel values similarity <br /> There 755 nodes 2575 interacting pairs             measure pairs. Example 3 shows input and <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                     Page 9 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> output values method described above, equivalent           represent abbreviated nucleotide sequences, inter- <br /> to Figure 3(b), using sequence data.                           act interact. The decision function, f (x, y), was <br />                                                                    previously obtained training process (see the <br /> Example 3. Given nucleotide sequences x1 , y1 , x2 , y2 ,          Pairwise support vector machine Section details). <br /> which represent abbreviated examples known genes             If resulting value evaluating decision function <br /> the dataset,                                                       f (x, y) greater 0, pair (x, y) interact, otherwise <br /> x1 = GCTAAATTGGACAAATCTCAATGAAATTGTC                               pair (x, y) interact. Suppose evaluation <br /> TTGG                                                               is <br /> y1 = ATGTCCTCGTCTTCGTCTACCGGGTACAGAA                               f (x, y) = f (CTCAAAGTCTTAATGCTTGGACAAATTGA <br /> AA                                                                 AATTGG . . . , TCTACAGAGTCGTCCTTCGTCTACCGG <br /> x2 = CATGACTAAAGAAACGATTCGGGTAGTTATT                               GAAAAT . . .) = +3. <br /> TGGCGG                                                             Then, predict nucleotide sequences (x, y) <br /> y2 = ATCTACAAGCGAACCAGAGTCTTCTGCAGGC                               interact context metabolic network the <br /> TTAGAT                                                             yeast Saccharomyces cerevisiae. <br /> the Tensor Product Pairwise Rational Kernel KPRKT                  In case, used 755 genes training pro- <br /> ((x1 , y1 ), (x2 , y2 )) obtained using 3-gram ratio-   cess, species 6000 genes [41]. <br /> nal kernel, e.g., z = TCT, values are:                     Then, rest metabolic pathways predicted <br />                                                                    classifying pairs genes (or pairs raw <br />   &#226;&#8364;&#162; cAx (z) = 2 because, TCT appears twice x1                   nucelotide sequences), interacting non-interacting, <br />        1 <br />     GCTAAATTGGACAAATCT CAATGAAATTG                                 using decision function f . Note decision func- <br />     TCT TGG,                                                       tion obtained training process, can <br />   &#226;&#8364;&#162; cAy (z) = 2 because, TCT appears twice y1                   used needed prediction process. <br />        1 <br />     ATGTCCTCGTCT TCGTCT ACCGGGTACAGA <br />     AAA,                                                             The advantage using sequence data nucleotide <br />   &#226;&#8364;&#162; cAx (z) = 1 because, TCT appears x2                    sequences used, annotated. <br />        2 <br />     CATGACTAAAGAAACGATTCT GGTAGTTATT                               Also, type sequence data, e.g., high- <br />     TGGCGG,                                                    throughput analysis, considered combined, <br />   &#226;&#8364;&#162; cAy (z) = 3 because, TCT appears times y2             using similar implementation. <br />        2 <br />     ATCT ACAAGCGAACCAGAGTCT TTCT GCAGG <br />     CTTAGAT.                                                       Experiment description performance measures <br />                                                                    We used pairwise SVM PRKs metabolic <br />   With results values corresponding                network prediction, using data algo- <br /> to 3-gram rational kernel, KPRKT computed as:               rithms described above. We ran experiments for <br /> KPRKT ((x1 , y1 ), (x2 , y2 )) = 0.3, 0.3 measure    different kernels. Firstly, used PRKs <br /> similarity.                                                        described Definition 1 using 3-gram rational <br />                                                                    kernel (i.e., KPRKDS&#226;&#710;&#8217;3gram , KPRKT&#226;&#710;&#8217;3gram , KPRKM&#226;&#710;&#8217;3gram <br /> SVM predicting process                                         KPRKC&#226;&#710;&#8217;3gram ). In addition, combination PRKs <br /> To implement pairwise SVM method, use                   kernels considered. We included the <br /> sequential minimal optimization (SMO) technique               phylogenetic kernel (Kphy ) described Yamanishi 2010 <br /> the package LIBSVM [40] combination OpenKer-               [9] PFAM kernel (Kpfam ) Ben-Hur et al. <br /> nel library [39]. During training process, decision        [22]. Then, second set experiments devel- <br /> function obtained estimating parameters,          oped combining PRKs phylogenetic kernel (i.e., <br /> shown Figure 3(c). Now, prediction process allows           KPRKDS&#226;&#710;&#8217;3gram + Kphy , KPRKT&#226;&#710;&#8217;3gram + Kphy , KPRKM&#226;&#710;&#8217;3gram + <br /> classification new pairs nucleotide sequences             Kphy KPRKC&#226;&#710;&#8217;3gram + Kphy ). Finally, combined <br /> interacting interacting evaluating decision          PRKs PFAM kernel, obtaining KPRKDS&#226;&#710;&#8217;3gram + <br /> function. Example 4 shows description prediction          Kpfam , KPRKT&#226;&#710;&#8217;3gram + Kpfam , KPRKM&#226;&#710;&#8217;3gram + Kpfam and <br /> process, similar process described Figure 3(d),          KPRKC&#226;&#710;&#8217;3gram + Kpfam kernels. Considering phy- <br /> but using nucleotide sequences.                                    logenetic PFAM kernels PDS, resulting <br />                                                                    combinations PDS [35]. <br /> Example 4. This example predictor process.              To compare advantages PRKs framework, <br /> Suppose want know                                         developed new set experiments same <br /> x = CTCAAAGTCTTAATGCTTGGACAAATTGAAAT                               dataset, using finite-state transducers. We <br /> TGG,                                                           considered pairwise (n-gram) kernel, i.e., KT&#226;&#710;&#8217;3gram . <br /> y=TCTACAGAGTCGTCCTTCGTCTACCGGGAAAAT,                               KT&#226;&#710;&#8217;3gram denoted pairwise tensor product described <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                          Page 10 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> in Pairwise kernels Section. To consistent                accuracy comparable Experiments II III. <br /> previous experiments, combined KT&#226;&#710;&#8217;3gram ker-                       Similar results obtained Yu et al. [29] PPI net- <br /> nel phylogenetic kernel (Kphy ) PFAM kernel                  works. They stated simple sequence-based kernels, such <br /> (Kpfam ), i.e., KT&#226;&#710;&#8217;3gram + Kphy KT&#226;&#710;&#8217;3gram + Kpfam ker-                 n-gram, properly predict-protein interactions. <br /> nels, respectively. The pairwise SVM algorithm used                   However, Yu et al. [29] combined sequence kernels <br /> to predict metabolic network using data set                  kernels incorporate evolutionary informa- <br /> described above. Table 1 describes groups created                  tion, accuracy model predictor improved. <br /> compare kernels equivalent PRKs.                           We obtained similar results applied metabolic net- <br />    All experiments executed PC intel                        works predictions: PHY PFAM kernels were <br /> i7CORE, 8MB RAM. To validate model, used                       included (Experiments II III, respectively), accuracies <br /> 10-fold cross validation method measured average                  improved maintaining adequate processing <br /> Area Under Curve Receiver Operating Characteris-                   times. The best accuracy value obtained com- <br /> tic (AUC ROC) score.                                                      bining PRK-Metric-3gram PFAM kernels (aver- <br />    Cross-validation method suitable approach val-                 age AUC=0.844). Other papers used similar kernel <br /> idate performance predictive models. In k-fold cross-                  combinations improve prediction biological net- <br /> validation, original dataset randomly partitioned                  works, Ben-Hur et al. [22] Yamanishi [9]. <br /> into k equal-sized subsets. Then, model trained k                  However, rational kernels used previous <br /> times. Each time, k subsets reserved                    research. <br /> testing remaining k &#226;&#710;&#8217; 1 subsets used                    Ben-Hur et al. [22] report average AUC value of <br /> training. The final value obtained average k             0.78 PFAM kernels, Yamanishi [9] reports an <br /> results (see Kohavi et al. [42] details).                        average AUC 0.77 PHY kernel predicting <br />    A Receiver Operating Characteristic (ROC) curve                   Saccharomyces cerevisiae metabolic pathways. We have <br /> plot True Positive Rate (TPR) versus False Pos-                previously developed similar experiments using SVM <br /> itive Rate (FPR) different possible cut-offs binary              methods [7]. As result, obtain AUC values 0.92 <br /> classifier system. A cut-off defines level discriminat-             PFAM kernel 0.80 PHY kernel, execution <br /> ing positive negative categories. ROC curve analysis                  times 12060 7980 seconds, respectively. However, <br /> is used assess overall discriminatory ability               cases random selection negative posi- <br /> SVM binary classifiers. The area curve (aver-                   tive training data used. As noted Yu et al. [29], <br /> age AUC score) used metric evaluate                  average AUC values obtained random selection of <br /> strength classification.                                           data training machine learning tools results bias <br />    In addition, 95% Confidence Intervals (CIs)                        genes (or proteins) large numbers inter- <br /> have computed, following method described                        actions. As such, high AUC results previous <br /> by Cortes Mohri [43]. The authors provide                           works directly compared results this <br /> distribution-independent technique compute confi-                      paper. We employed balanced sampling tech- <br /> dence intervals average AUC values. The variance                      niques suggested Yu et al. [29] combat bias the <br /> depends number positive negative examples                     training set. Our results, average AUC values the <br /> (2575 2574 cases) number classifica-                range 0.5-0.844, comparable exceed cases the <br /> tion errors, ranging 889 1912 cases.                   results obtained Yu et al. [29] balanced sampling, <br />                                                                           range 0.5-0.75 different kernels <br /> Results discussion                                                    protein interaction problems. We obtained <br /> Table 2 shows SVM performance, execution times                    results execution times 15-140 seconds. With <br /> 95% CIs grouped kernels mentioned above. As                     exception direct sum kernel, con- <br /> can see, experiments using PRK best                 fidence intervals behaviour random <br /> execution times (Exp. I) transducer representations                classifier. <br /> and algorithms speed processing. However,                        We developed experiment PFAM <br />                                                                           kernel simple kernel Pairwise Tensor Product <br /> Table 1 Groups PRK pairwise kernel comparison                     (Kpfam ) using balanced sampling suggested Yu <br />                                                                           et al. [29]. Note PRK; regular <br /> Group             PRKs 1                              Pairwise Kernel 2 <br />                                                                           pairwise kernel using PFAM simple kernel, similar <br /> N-GRAM            KPRKT&#226;&#710;&#8217;3gram                         KT&#226;&#710;&#8217;3gram            example Using pairwise kernel SVM <br /> PHY               KPRKT&#226;&#710;&#8217;3gram +Kphy                   KT&#226;&#710;&#8217;3gram + Kphy     predict metabolic networks Section. As result, the <br /> PFAM              KPRKT&#226;&#710;&#8217;3gram +Kpfam                  KT&#226;&#710;&#8217;3gram + Kpfam    average AUC 0.61 execution time 122 <br /> 1 <br />   Kernels taken Table 2. <br />                                                                           seconds. When compare values results <br /> 2 <br />   Computed Tensor Product Pairwise Kernel.                       Table 2 Exp. I, kernels KPRKM&#226;&#710;&#8217;3gram <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                           Page 11 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Table 2 Average AUC ROC scores processing times various PRKs <br /> Exp        Type kernels      Kernel                                         Average AUC score   Runtime (sec)    Confidence intervals <br />            Pairwise Rational    PRK-Direct-Sum (KPRKDS&#226;&#710;&#8217;3gram )                 0.499               15.0             [0.486, 0.512] <br />            Kernels (PRK)        PRK-Tensor-Product (KPRKT&#226;&#710;&#8217;3gram )              0.597               16.2             [0.589, 0.605] <br /> I <br />            (3-gram)             PRK-Metric-Learning (KPRKM&#226;&#710;&#8217;3gram )             0.641               17.4             [0.633, 0.648] <br />                                 PRK-Cartesian (KPRKC&#226;&#710;&#8217;3gram )                   0.640               15.0             [0.632, 0.647] <br />            PRKs combined        PRK-Direct-Sum+Phy (KPRKDS&#226;&#710;&#8217;3gram + Kphy )      0.425               136.2            [0.411, 0.438] <br />            phylogenetic    PRK-Tensor+Phy (KPRKT&#226;&#710;&#8217;3gram +Kphy )            0.733               135.6            [0.725, 0.741] <br /> II <br />            data (Kphy Non-      PRK-Metric+Phy (KPRKM&#226;&#710;&#8217;3gram +Kphy )            0.761               139.2            [0.753, 0.768] <br />            sequence kernel)     PRK-Cartesian+Phy (KPRKC&#226;&#710;&#8217;3gram +Kphy )         0.742               132.6            [0.734, 0.749] <br />            PRKs combined        PRK-D-Sum+PFAM (KPRKDS&#226;&#710;&#8217;3gram +Kpfam )          0.493               136.2            [0.480, 0.506] <br />            PFAM data       PRK-Tensor+PFAM (KPRKT&#226;&#710;&#8217;3gram +Kpfam )          0.827               136.8            [0.819, 0.834] <br /> III <br />            (Kpfam               PRK-Metric+PFAM (KPRKM&#226;&#710;&#8217;3gram +Kpfam )          0.844               140.4            [0.837, 0.850] <br />            Sequence kernel)     PRK-Cartesian+PFAM (KPRKC&#226;&#710;&#8217;3gram +Kpfam )       0.842               132.0            [0.835, 0.849] <br />  <br />  <br />  <br /> and KPRKC&#226;&#710;&#8217;3gram better average accuracy (i.e., 0.641                   classification methods. McNemar&#226;&#8364;&#8482;s test defines a <br /> and 0.640, respectively) lesser average execution                      z score, calculated as: <br /> times (17.4 15.0 seconds, respectively). In addition,                                                 <br />                                                                                        |Nsf &#226;&#710;&#8217; Nfs | &#226;&#710;&#8217; 1 <br /> when Pairwise Rational Kernel 3-gram combined                           z =                                              (2) <br />                                                                                                        <br /> with PFAM kernel Exp. III, (i.e., Tensor                                        Nsf + Nfs <br /> Product Pairwise Rational Kernel - KPRKT&#226;&#710;&#8217;3gram +Kpfam ), <br /> the average accuracy value (average AUC=0.827)                          Nfs number times Algorithm A failed <br /> better Pairwise Tensor Product (Kpfam ),                     Algorithm B succeeded, Nsf number of <br /> the execution time just increased 14.8 seconds (i.e.,                   times Algorithm A succeeded Algorithm B failed. <br /> from 122 seconds, using Kpfam , 134.8 seconds, using                     When z equal 0, algorithms similar <br /> KPRKT&#226;&#710;&#8217;3gram +Kpfam ).                                                       performance. Additionally, Nfs larger Nsf then <br />   In order statistically compares theses results,                     Algorithm B performs better Algorithm A, vice <br /> applied McNemar&#226;&#8364;&#8482;s non-parametric statistical test                       versa. We computed z scores considering Algorithm A <br /> [44]. McNemar&#226;&#8364;&#8482;s tests recently used Bostanci                   SVM algorithm using Pairwise Tensor Product <br /> et al. [45] prove significant statistical differences                    (Kpfam ) different Algorithm Bs, using SVM <br />  <br />  <br />  <br />  <br />      Figure 4 Comparison pairwise rational kernels pairwise kernels grouped kernel types (N-GRAM group, PHY group and <br />      PFAM group). <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                             Page 12 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> with different PRKs Table 2 (i.e., KPRKM&#226;&#710;&#8217;3gram ,   used similar types stochiometric data, be <br /> KPRKC&#226;&#710;&#8217;3gram KPRKT&#226;&#710;&#8217;3gram +Kpfam mentioned above).          converted kernels consider PRKs. <br /> In cases, obtained z scores greater 0 (i.e., <br /> 4.73, 4.54, 7.51), mean PRKs performed better.      Conclusion <br /> These z-score proved difference statis-     In paper, introduced new framework called <br /> tically significant confidence level 99% (based     Pairwise Rational Kernels, pairwise kernels are <br /> on Two-tailed Prediction Confidence Levels described          obtained based transducer representations, i.e., ratio- <br /> by [45]).                                                     nal kernels. We defined framework, developed general <br />    The Cartesian Kernel widely used        algorithms tested pairwise Support Vector <br /> it defined Kashima et al. [10]. Kashima et al. [10]    Machine method predict metabolic networks. <br /> used Expression, Localization, Chemical Phylogenetic        We used dataset yeast Saccharomyces cere- <br /> kernels predict metabolic networks. Each          visiae validate compare proposal similar <br /> are non-sequence kernels. In current experiments          models using data species. We obtained <br /> we computed, time, pairwise Cartesian ker-      better execution times models, while <br /> nel rational kernel (sequence kernel) repre-        maintaining adequate accuracy values. Therefore, PRKs <br /> sent sequence data metabolic network prediction.          improved performance pairwise-SVM algo- <br /> Cartesian kernels [10] defined alternative    rithm used training process supervised <br /> to improve Tensor Product Pairwise Kernel [22] com-       network inference methods. <br /> putation performance. In experiments shown         In methods, learning process executed <br /> Table 2, confirmed definition, obtained    obtain decision function. The decision func- <br /> better accuracy execution times used          tion used times necessary predict <br /> Cartesian Pairwise Rational Kernel (KPRKC&#226;&#710;&#8217;3gram )      interaction sequences species <br /> than Tensor Product Rational Kernel (KPRKT&#226;&#710;&#8217;3gram ).       predict metabolic pathways. <br /> Comparing results Kashima et al. [10],              The methods research used sequence data <br /> obtained better average AUC values (i.e., 0.844 vs 0.79),     (e.g., nucleotide sequences) predict interactions. <br /> and approximately average execution           Genes need correctly annotated raw <br /> times (i.e., 93 seconds). Kashima et al. [10] used non-       sequences used. Therefore, methods were <br /> sequence data random selection positive nega-      able avoid error accumulation wrong gene <br /> tive data training.                                       annotations. <br />    Figure 4 shows results experiments compar-        As future work, proposal used produce a <br /> ing PRK framework pairwise kernels. The        set candidate interactions pathways same <br /> three comparative groups described Table 1 used.      species, experimentally validated. <br /> As seen, execution times better      As well, pairwise rational kernels developed <br /> PRKs used groups. This proves PRKs      using finite-state transducers operations. <br /> compute faster rational kernels use finite-state <br /> transducer operations representations, improving      Competing interests <br />                                                               The authors declare competing interests. <br /> performance. <br />    The power using kernels sort         Authors&#226;&#8364;&#8482; contributions <br /> of data represented using kernels. Therefore,          ARL implemented algorithms developed experiments. ARL, MD <br />                                                               BF contributed equally drafting manuscript. All authors have <br /> completely disparate types data combined         reviewed approved final version manuscript. <br /> add power kernel-based machine learning methods <br /> [8]. For example, coefficients describing relative amounts    Acknowledgements <br />                                                               This work funded Natural Sciences Engineering Research Council of <br /> of metabolites involved biochemical reaction (i.e.,      Canada (NSERC) Microbial Genomics Biofuels Co-Products from <br /> stochiometric data) represented ker-           Biorefining Processes (MGCB2 project). <br /> nels added strength predicting model. For <br /> example, reaction catalyzed fructose-bisphosphate      Author details <br />                                                               1 Department Computer Science, University Manitoba, Winnipeg, <br /> aldolase [EC 4.1.2.13] splits 1 molecule fructose          Manitoba, Canada. 2 Department Plant Science, University Manitoba, R3T <br /> 1,6-bisphosphate 2 molecules glyceraldehyde           2N2 Winnipeg, Manitoba, Canada. <br /> 3-phosphate, relative amounts substrate <br />                                                               Received: 11 April 2014 Accepted: 23 September 2014 <br /> and product represented coefficients 1         Published: 26 September 2014 <br /> 2, respectively. A stoichiometric kernel would <br /> encode coefficients substrates products,    References <br />                                                               1. Faust K, Helden J: Predicting metabolic pathways sub-network <br /> enzymes interact stoichiometric            extraction. In Bacterial Molecular Networks. Methods Molecular Biology. <br /> coefficients 0. Other authors [46-48] defined         Springer: New York; 2012:107&#226;&#8364;&#8220;130. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                                                   Page 13 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> 2.    Beurton-Aimar M, Nguyen TV-N, Colombi&#195;&#169; S: Metabolic network                   26. Hofmann T, Sch&#195;&#182;lkopf B, Smola AJ: Kernel methods machine <br />       reconstruction topological analysis. In Plant Metabolic Flux            learning. In The annals statistics. New York: JSTOR; 2008: <br />       Analysis. Springer: New York; 2014:19&#226;&#8364;&#8220;38.                                         1171&#226;&#8364;&#8220;1220. <br /> 3.    Osterman A, Overbeek R: Missing genes metabolic pathways:                27. Leslie CS, Eskin E, Cohen A, Weston J, Noble WS: Mismatch string <br />       comparative genomics approach. Curr Opin Chem Biol 2003,                          kernels discriminative protein classification. Bioinformatics 2004, <br />       7(2):238&#226;&#8364;&#8220;251.                                                                     20(4):467&#226;&#8364;&#8220;476. <br /> 4.    Karp PD, Latendresse M, Caspi R: The pathway tools pathway                    28. Mohri M: Weighted automata algorithms. In Handbook Weighted <br />       prediction algorithm. Stand Genomic Sci 2011, 5(3):424&#226;&#8364;&#8220;429.                       Automata. New York: Springer; 2009:213&#226;&#8364;&#8220;254. <br /> 5.    Latendresse M, Paley S, Karp PD: Browsing metabolic regulatory            29. Yu J, Guo M, Needham CJ, Huang Y, Cai L, Westhead DR: Simple <br />       networks biocyc. In Bacterial Molecular Networks. Springer: New              sequence-based kernels predict protein&#226;&#8364;&#8220;protein <br />       York; 2011:197&#226;&#8364;&#8220;216.                                                               interactions. Bioinformatics 2010, 26(20):2610&#226;&#8364;&#8220;2614. <br /> 6.    Caspi R, Altman T, Dreher K, Fulcher CA, Subhraveti P, Keseler IM,            30. Basilico J, Hofmann T: Unifying collaborative content-based <br />       Kothari A, Krummenacker M, Latendresse M, Mueller LA: The metacyc                 filtering. In Proceedings Twenty-first International Conference on <br />       database metabolic pathways enzymes biocyc                         Machine Learning. Helsinki, Finland: ACM; 2004:9. <br />       collection pathway/genome databases. Nucleic Acids Res 2012,               31. Oyama S, Manning CD: Using feature conjunctions examples <br />       40(D1):742&#226;&#8364;&#8220;753.                                                                   learning pairwise classifiers. In Machine Learning: ECML 2004. New <br /> 7.    Roche-Lima A, Domaratzki M, Fristensky B: Supervised learning                     York: Springer; 2004:322&#226;&#8364;&#8220;333. <br />       methods infer metabolic network using sequence                         32. Brunner C, Fischer A, Luig K, Thies T: Pairwise support vector machines <br />       non-sequence kernels. In Proceeding International Workshop                  application large scale problems. J Mach Learn Res 2012, <br />       Machine Learning System Biology, Conference ISMB/ECCB&#226;&#8364;&#8482;13. Berlin,              13:2279&#226;&#8364;&#8220;2292. <br />       Germany; 2013.                                                                33. Cortes C, Vapnik V: Support-vector networks. Mach Learn 1995, <br /> 8.    Fu Y: Kernel methods applications bioinformatics. In                       20(3):273&#226;&#8364;&#8220;297. <br />       Handbook Bio-Neuroinformatics. Germany: Springer Berlin-Heidelberg;        34. Gomez SM, Noble WS, Rzhetsky A: Learning predict protein&#226;&#8364;&#8220;protein <br />       2014:275&#226;&#8364;&#8220;285.                                                                     interactions protein sequences. Bioinformatics 2003, <br /> 9.    Yamanishi Y: Supervised inference metabolic networks                  19(15):1875&#226;&#8364;&#8220;1881. <br />       integration genomic data chemical information. In Elements          35. Horn RA, Johnson CR: Matrix Analysis. United Kingdom: Cambridge <br />       Computational Systems Biology. USA: Wiley; 2010:189&#226;&#8364;&#8220;212.                          University Press; 2012. <br /> 10.   Kashima H, Oyama S, Yamanishi Y, Tsuda K: Cartesian kernel: An                36. Sikorski RS, Hieter P: A shuttle vectors yeast host strains <br />       efficient alternative pairwise kernel. IEICE Trans Inform Syst             designed efficient manipulation dna saccharomyces <br />       2010, 93(10):2672&#226;&#8364;&#8220;2679.                                                           cerevisiae. Genetics 1989, 122(1):19&#226;&#8364;&#8220;27. <br /> 11.   Kotera M, Yamanishi Y, Moriya Y, Kanehisa M, Goto S: GENIES: gene             37. Kanehisa M, Araki M, Goto S, Hattori M, Hirakawa M, Itoh M, Katayama T, <br />       network inference engine based supervised analysis. Nucleic Acids              Kawashima S, Okuda S, Tokimatsu T: KEGG linking genomes <br />       Res 2012, 40(W1):162&#226;&#8364;&#8220;167.                                                         life environment. Nucleic Acids Res 2008, 36(suppl 1): <br /> 12.   Ben-Hur A, Ong CS, Sonnenburg S, Sch&#195;&#182;lkopf B, R&#195;&#164;tsch G: Support                   480&#226;&#8364;&#8220;484. <br />                                                                                     38. Allauzen C, Riley M, Schalkwyk J, Skut W, Mohri M: Openfst: A general and <br />       vector machines kernels computational biology. PLoS <br />                                                                                         efficient weighted finite-state transducer library. In Implementation <br />       Comput Biol 2008, 4(10):1000173. <br />                                                                                         Application Automata. New York: Springer; 2007:11&#226;&#8364;&#8220;23. <br /> 13.   Yamanishi Y, Vert JP, Kanehisa M: Protein network inference from <br />                                                                                     39. Allauzen C, M <br /> </body></html>