<?xml version="1.0" encoding="UTF-8"?><html xmlns="http://www.w3.org/1999/xhtml" xmlns:oboInOwl="http://www.geneontology.org/formats/oboInOwl#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:obo="http://purl.obolibrary.org/obo/" xmlns:owl="http://www.w3.org/2002/07/owl#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:dublincorens="http://purl.org/dc/elements/1.1/"  version="XHTML+RDFa 1.0" ><body> <br /> Metabolic network prediction pairwise rational kernels <br />  <br />  <br />  <br />   Abstract <br />   Background: Metabolic networks represented set metabolic pathways. Metabolic pathways series <br />   biochemical reactions, product (output) reaction serves substrate (input)   reaction. pathways remain incompletely characterized. major challenges computational biology   obtain better models metabolic pathways. Existing models dependent annotation genes.   propagates error accumulation pathways predicted incorrectly annotated genes. Pairwise <br />   classification methods supervised learning methods used classify new pair entities.   classification methods, e.g., Pairwise Support Vector Machines (SVMs), use pairwise kernels. Pairwise kernels   similarity measures pairs entities. Using pairwise kernels handle sequence data requires long <br />   processing times large storage. Rational kernels kernels based weighted finite-state transducers   represent similarity measures sequences automata. effectively used problems   handle large sequence information protein essentiality, natural language processing machine <br />   translations. <br />   Results: create new family pairwise kernels using weighted finite-state transducers (called Pairwise Rational <br />   Kernel (PRK)) predict metabolic pathways variety biological data. PRKs advantage simpler <br />   representations faster algorithms transducers. raw sequence data used, predictor model <br />   avoids errors introduced incorrect gene annotations. developed experiments PRKs   Pairwise SVM validate methods using metabolic network Saccharomyces cerevisiae. result, PRKs <br />   used, method executes faster comparison pairwise kernels.  use PRKs combined <br />   simple kernels include evolutionary information, accuracy values improved,   maintaining lower construction execution times. <br />   Conclusions: power using kernels sort data represented using kernels.  <br />   completely disparate types data combined add power kernel-based machine learning methods.   compared proposal using PRKs similar kernel, execution times decreased,   compromise accuracy. proved combining PRKs kernels include evolutionary <br />   information, accuracy improved. proposal use type sequence data, genes   need properly annotated, avoiding accumulation errors incorrect previous annotations. <br />   Keywords: Metabolic network, Pairwise rational kernels, Supervised network inference, Finite-state transducers, <br />   Pairwise support vector machine <br />  <br />  <br />  <br />  <br /> Background                                                       Yamanishi [9] Kotera et al. [11] described Related work                                                   theory implementation GENIES, web applica- <br /> Metabolic networks allow modelling molecular sys-       tion allowed prediction unknown parts tems understand underlying biological mechanisms        metabolic networks using supervised graph inference cell [1]. Metabolic networks represented set   kernel methods. algorithms implemented metabolic pathways. Metabolic pathways series      GENIES decision predictive func- <br /> biochemical reactions, product (output)      tions supervised network inference. reaction serves substrate (input)        algorithms Kernel Canonical Correlation Analysis <br /> reaction. experimental determination metabolic          (KCCA) [13,14], Expectation-Maximization (EM) algo- <br /> networks, based known biological data DNA           rithm [15] Kernel Matrix Regression (KMR) [9]. protein sequences, gene expression data,   authors developed experiments, did challenging [2].  efforts      use sequence data.  motivations develop supervised learning methods determine genes         extend previous research [7] use sequence <br /> coding missing enzymes predict unknown parts        data combined algorithms. noted  metabolic networks [3,4].                                      obtained best accuracy values SVM method <br />   methods predict metabolic networks            combined sequence kernels, high execution <br /> assume genome annotation correct, e.g., Path-      times. <br /> way Tools [4], software application predict metabolic       address high computational costs,  <br /> networks using information BioCyc databases [5].          sider results Allauzen et al. [16], proposed <br /> Pathway Tools uses algorithm,         method predict protein essentiality using SVMs 1 infers reactions catalyzed organism          manipulating sequence data using rational kernels. set enzymes present annotated genome,            authors designed sequence kernels (called general 2 infers metabolic pathways present        domain-based kernels), instances rational <br /> organism reactions 1.           kernels. handle large data (6190 domains <br /> sidering BioCyc MetaCyc huge              3000 protein sequences), automata rep- <br /> available data, application potentially make pre-     resentation used create rational kernels. cise metabolic pathway predictions [6].           results showed final kernels favourably predicted <br /> 2 based annotated genes,            protein essentiality. note,  errors annotation, inferred pathways           previous works using rational kernels bioinformatics correct.  methods intrinsically         [16-18] considered problems related biological <br /> carry error accumulations incorrect genome              network predictions. <br /> annotations.                                                     Based fact rational kernels described   tackle problem, previously proposed          Allauzen et al. [16] extended problems, <br /> using information directly related sequence          define new kernels applied metabolic network primary data (e.g., genomic proteomic data)            predictions. research, represent sequence data <br /> [7]. result, obtained best accuracy values         using rational kernels. Rational kernels advantage using Support Vector Machine (SVM) methods combined            fast algorithms  efficient representation  <span id='am-11' about='xsd:string' typeof='owl:Thing'>string</span> kernels representing sequence data.         transducers sequence manipulations improve  <br /> experimentally demonstrated SVMs supersede          formance. sequence data used, raw genomic <br /> methods, matrix kernel regression, predict-        proteomic information considered, ing metabolic networks. consistent recent         method avoids problems associated incorrect anno- <br /> results showing usefulness SVMs bioinformatics       tation predicting metabolic networks. Additionally, <br /> [8].  solution [7] computationally expen-      current work combine rational kernels <br /> sive terms execution time sequence data       (using finite-state transducers) [17-20] known pair- <br /> manipulation.                                                  wise kernels [10,21-23] obtain pairwise rational kernels. <br />   authors combined SVM               kernel techniques proposed paper supervised learning techniques kernel methods          applied equally machine learning tools predict metabolic networks [9-11]. main advantage          employ kernel methods, KCCA, EM KMR, using kernel methods heterogeneous data         focused SVMs illustration capabil- represented combined simultaneously.            ity reduce computational costs. chosen <br /> disparate types data manipulated kernels,         SVM methods light experimental results data sources contribute uni-          obtained previous works [7], efficiency <br /> formly information training set building    effectiveness SVM methods predict protein <br /> model [12].                                                    essentiality [16]. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                      Page 3 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Automata transducers                                             example, weighted transducer shown Automata define mathematical formalism analyze            Figure 1 . use delimiters colon sepa- <br /> model real problems useful machines [24].               rate input output labels transitions automaton set states (generally represented            slash separate weight values  e., nota- <br /> circles), transitions (generally represented arrows).       tion input:output/weight). States represented automaton moves state state                circles, set initial states bold circles (makes transition) activated event func-           set final states double circles. ini- <br /> tion. variant automaton called finite state           tial final states associated weighs  notation <br /> machine. finite-state machine used model               state/weight). Example 1 shows compute simple  turnstiles transit lights,          weight transducer T  e., T(x, y)) given <br /> complex systems sophisticated spaceship controls           sequences x y. case, define alphabets <br /> [25].                                                                = {G, C}   = {G, C}. <br />    Automata work sequence symbols,   &#226;&#710;&#8212; <br /> denotes finite sequences using symbols          Example 1. weight  value) associated trans- <br /> alphabet  , including   represents sym-             ducer T Figure 1  pair (x, y) = (GGC, CCG) &#226;&#710;&#710; <br /> bol. order formally define automata transducers,           &#226;&#710;&#8212; &#195;&#8212;  &#226;&#710;&#8212; computed  follow notations used Cortes et al. [17].             T(GGC, CCG) = 1 &#226;&#710;&#8212; 2 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 6 &#226;&#710;&#8212; 1 + 1 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 1 &#226;&#710;&#8212; 4 &#226;&#710;&#8212; 1 = 48, <br /> automaton 5-tuple ( , Q,  F, &#206;&#180;) [24]         considering accepting paths labelled <br /> input alphabet set, Q state set, &#226;&#352;&#8218; Q subset        input GCC output CCG. paths  initial states, F &#226;&#352;&#8218; Q subset final states,             Path 1 : State 0   &#226;&#8224;&#8217; State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 3, <br /> &#206;&#180; &#226;&#352;&#8224; Q &#195;&#8212; (  &#226;&#710;&#170; { }) &#195;&#8212; Q transition set. transition               Path 2 : State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 2   &#226;&#8224;&#8217; State 3. <br /> &#206;&#185; &#226;&#710;&#710; &#206;&#180; describes actions moving state            initial final values terms T(GGC, CCG) condition (input symbol) encountered.            correspond weights initial final <br />    Similarly, Finite-State Transducer (FST) automa-        states. <br /> ton output <span id='am-20' about='rdfs:label' typeof='owl:Thing'>label</span> included transition addition input label. Based <span id='am-10' about='obo:IAO_0000115' typeof='owl:Thing'>definition</span>,          Figure 1(b) shows graph representation weighted FST T 6-tuple ( ,  , Q,  F, &#206;&#180;) [18], new        automaton. obtained output projection term   output alphabet transition set &#206;&#180;          transducer T input labels omitted.  &#206;&#180; &#226;&#352;&#8224; Q &#195;&#8212; (  &#226;&#710;&#170; { }) &#195;&#8212; (  &#226;&#710;&#170; { }) &#195;&#8212; Q. Similar pre-         alphabet     = {G, C} weight computation <br /> vious definition, transition &#206;&#185; &#226;&#710;&#710; &#206;&#180; action moving       automaton given sequences shown state input symbol               Example 2. encountered output   produced. <br />    addition, Automata Finite-State Transducers          Example 2. weight  value) associated weighted, transition labelled              Automaton Figure 1(b) y = CCG &#226;&#710;&#710;  &#226;&#710;&#8212; com- <br /> weight.  Weighted Automaton (WA) 7-tuple               puted  <br /> ( , Q,  F, &#206;&#180;, &#206;&#187;, &#207;?) Weighted Finite-State Transducer            CCG) = 1 &#226;&#710;&#8212; 2 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 6 &#226;&#710;&#8212; 1 + 1 &#226;&#710;&#8212; 3 &#226;&#710;&#8212; 1 &#226;&#710;&#8212; 4 &#226;&#710;&#8212; 1 = 48 <br /> (WFST) 8-tuple ( ,  , Q,  F, &#206;&#180;, &#206;&#187;, &#207;?) [18],       considering accepting paths labelled <br /> new terms &#206;&#187; &#207;?  &#206;&#187; : &#226;&#8224;&#8217; R, initial weight func-         CCG. paths  <br /> tion, &#207;? : F &#226;&#8224;&#8217; R, final weight function. new                 Path 1 : State 0   &#226;&#8224;&#8217; State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 3, <br /> transitions WFSTs &#206;&#180; &#226;&#352;&#8224; Q&#195;&#8212;( &#226;&#710;&#170;{ })&#195;&#8212;                    Path 2 : State 0   &#226;&#8224;&#8217; State 1   &#226;&#8224;&#8217; State 2   &#226;&#8224;&#8217; State 3. <br /> R&#195;&#8212;Q &#206;&#180; &#226;&#352;&#8224; Q&#195;&#8212;( &#226;&#710;&#170;{ })&#195;&#8212;( &#226;&#710;&#170;{ })&#195;&#8212;R&#195;&#8212;Q, respectively,                   initial final values terms CCG) R represents weights real numbers.                    correspond weights initial final states. <br />  <br />  <br />  <br />  <br />  Figure 1 Weighted transducer weighted automaton representing sequences alphabet   =   = {G, C}.   Weighted <br />  Transducer T. (b) Weighted Automaton  obtained projecting output T). <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                      Page 4 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />   operations defined automata                 Using Algorithm 1, overall complexity com- <br /> transducers, inverse composition. Given             pute value rational kernel O(|U||Mx | |), <br /> transducer T, inverse T &#226;&#710;&#8217;1 transducer obtained           |U| remains constant. practice, complexity input output labels swapped               reduced O(|U| + |Mx | +  |) kernels transition. composition operation transduc-              used areas natural language process- <br /> ers T1 T2 input output alphabets                  ing computational biology. example, Algorithm 1 <br /> equal   weighted transducer, denoted T1 &#226;&#8212;&#166;                n-gram kernel linear complexity   2 , provided sum given (T1 &#226;&#8212;&#166; T2 )(x, y) = <br /> T                                                                   detailed description n-gram kernel . <br />      &#226;&#710;&#8212; T1 (x, T2   y) defined R (x, y) &#226;&#710;&#710;      Kernels used training methods discriminant clas- <br />  &#226;&#710;&#8212;.                                                                 sification algorithms (e.g., SVM) need satisfy Mercer&#226;&#8364;&#8482;s <br />                                                                     condition equivalently Positive Definite Sym- <br /> Rational kernels                                                    metric - PDS [18]. Cortes et al. [18] proven result order manipulate sequence data, FSTs provide sim-           gives general method construct PDS rational <br /> ple representation efficient algorithms          kernel using WFSTs. <br /> composition shortest-distance [18]. Rational Kernels, <br /> based Finite-State Transducers, effective ana-           Theorem 1. ([18]). T arbitrary weighted trans- <br /> lyzing sequences variable lengths [17].                        ducer, U = T &#226;&#8212;&#166; T &#226;&#710;&#8217;1 defines PDS rational kernel. <br />   formal definition, function k :   &#226;&#710;&#8212; &#195;&#8212;  &#226;&#710;&#8212; &#226;&#8224;&#8217; R rational kernel exists WFST U k           n-gram kernel rational kernel <br /> coincides function defined U, e., k(x, y) =           Hofmann et al. [26] defined class similarity mea- <br /> U(x, y) sequences x, y &#226;&#710;&#710;   &#226;&#710;&#8212; &#195;&#8212;  &#226;&#710;&#8212; [17].            sures biological sequences function  consider input output alphabets             number equal subsequences  symbols  e.,   =  ), terms     &#226;&#710;&#8212;            example measures spectrum kernel defined used.                                                       Leslie et al. [27]. Similarity values results   order compute value U(x, y) partic-            summing products counts sub- <br /> ular pair sequences x, y &#226;&#710;&#710;   &#226;&#710;&#8212; &#195;&#8212;   &#226;&#710;&#8212; , composition           sequences. referred computational biology <br /> algorithm weighted transducers used [17]:                     k-mer n-gram kernel. rest paper,                                                                     use term n-gram follow notation Hofmann <br />   &#226;&#8364;&#162;  Mx , considered trivial weighted <br />                                                                     et al. [26] Cortes et al. [17]. <br />     transducers representing x, y respectively,     Mx (x, x) = 1 Mx (v, w) = 0 v  <br />  = x w  <br />  = x.          n-gram kernel defined kn (x, y)                  = <br />                                                                         =n cx  cy   fixed integer n, represents <br />     Mx obtained using linear finite automata <br />                                                                     subsequences length n.  ca (b) number     representing x augmenting transition                                                                     times subsequence b appears  kn     output label identical input label setting <br />                                                                     represented rational kernel using weighted trans- <br />     transition, initial final weights                                                                      ducer = Tn &#226;&#8212;&#166; Tn&#226;&#710;&#8217;1 , transducer Tn defined <br />     obtained similar way using y. <br />                                                                     Tn (x,  = cx  , x, &#226;&#710;&#710;     &#226;&#710;&#8212;   = n [18]. <br />   &#226;&#8364;&#162;  definition weighted transducer <br />                                                                     example, n = 2, k2 (x, y) =  =2 cx  cy       composition: <br />                                                                     rational kernel represents subsequences <br />     (Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; )(x, y) = Mx (x, x)U(x, y (y, y). <br />                                                                       &#226;&#710;&#8212; size 2 T2 (x,  = cx   counts     Considering Mx (x, x) = 1 (y, y) = 1,                                                                     times occurs x. <br />     obtain (Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; )(x, y) = k(x, y), e., sum                                                                       Allauzen et al. [16] extended construction     weights paths Mx &#226;&#8212;&#166; U &#226;&#8212;&#166; exactly <br />                                                                     kernel, kn , measure similarity     U(x, y) = k(x, y). <br />                                                                     sequences represented automata. Firstly, define <br />   Based representation, step algorithm             count      sequence weighted automaton defined Cortes et al. [17] obtain k(x, y) = U(x, y).          cA   =         u&#226;&#710;&#710;  &#226;&#710;&#8212; cu  u), u ranges                                                                     set sequences   &#226;&#710;&#8212; represented                                                                     automaton  equation represents sums <br />                                                                     obtained u, times occurs Algorithm 1 Rational Kernel Computation                             u multiplied weight  value) associated INPUT: pair sequences (x, y) WFST U                        sequence u automaton  computed   compute N using composition N = Mx &#226;&#8212;&#166; U &#226;&#8212;&#166;                  Example 2). <br /> (ii) compute sum paths N using                           similarity measure weighted <br /> shortest-distance algorithm, equal U(x, y).             automata A1 A2 , according n-gram kernel kn , RESULTS: value k(x, y) = U(x, y)                                 defined  <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                           Page 5 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />                         <br />     kn (A1 , A2 ) =           (A1 &#226;&#8212;&#166; Tn &#226;&#8212;&#166; Tn&#226;&#710;&#8217;1 &#226;&#8212;&#166; A2 )(x, y)             di binary values (e.g., pair (xi , yj ) classified                       x,y&#226;&#710;&#710;X                                            +1 &#226;&#710;&#8217;1), = 1, . . . , n, j = 1, . . . , n mapping <br />                                                                        function 	, Pairwise SVM methods opti- <br />                  =            cA1  cA2                      (1) <br />                                                                        mal hyperplane, wT 	(xi , yi ) + b = 0, separate                        =n <br />                                                                        points categories. solutions based   Based definition using Algorithm 1,                  dual formalism optimization problem described <br /> n-gram rational kernel constructed time                      Cortes et al. [33]. case decision function  <br /> O( | + |Mx | +  |), described Allauzen et al. [16]                           n                              Mohri et al. [28].                                                       f (x, y) =       &#206;&#177;ij K (xi , yj ), (x, y) + b, <br />                                                                                             j <br />   Yu et al. [29] verified n-gram sequence kernels good predict protein interactions. address concerns experiments combin-                K pairwise kernel, (xi , yj ) set train- <br /> ing n-gram kernels include evolutionary                ing examples, &#206;&#177; obtained Lagrange Multipliers <br /> information.                                                           function w  normal vector) b offset <br />                                                                        hyperplane   Cortes et al. [33] Pairwise kernels <br />                                                                        details). case, &#206;&#177; b &#226;&#8364;&#339;learned&#226;&#8364;? parame- apply kernel methods problem predicting <br />                                                                        ters training process.  f classifies new <br /> relationships given entities, e., pairwise pre- <br />                                                                        pairs (x, y). example, f (x, y) &gt;= 0, (x, y) classified <br /> diction. Models solve problem input <br />                                                                        +1, (x, y) classified &#226;&#710;&#8217;1. instances, output relationship  Kernels used models need define simi-                Metabolic networks <br /> larities arbitrary pairs entities. Typically,           work, metabolic network represented construction pairwise kernels K based simple             graph, vertices enzymes, kernels k, k : X &#195;&#8212; X &#226;&#8224;&#8217; R. paper differ-             edges enzyme-enzyme relations  proteins ent pairwise kernels investigated: Direct Sum Learning             enzymes catalyze successive reactions known path- <br /> Pairwise Kernel [21], Tensor Learning Pairwise Kernel               ways). Figure 2 represents graphical transition Kronecker Kernel) [22,30,31], Metric Learning Pairwise                 metabolic pathway graph. <br /> Kernel [23] Cartesian Pairwise Kernel [10].                           traditional representation metabolic path- <br />   pairwise functions guarantee symmetry                  way, enzymes vertices (nodes), metabolites pairwise kernels K, e., K((x1 , y1 ), (x2 , y2 )) =           edges (branches). Following Yamanishi [9], represent <br /> K((x2 , y2 ), (x1 , y1 )), x1 , x2 , y1 , y2 &#226;&#710;&#710; X.    differently, interactions pairs simple kernel k PDS (satisfies Mercer condition),               enzymes considered discrete data points. exam- resulting pairwise kernel K PDS,               ple, Figure 2 , enzyme numbered EC 5.3.1.9 pairwise kernels defined [10,32].                            create <span id='am-5' about='obo:IMR_0200474' typeof='owl:Thing obo:IMR_0001657 obo:IMR_0000947 obo:IMR_0000001 obo:IMR_0002125'><span id='am-6' property="oboInOwl:hasOBONamespace" content="molecule_role" datatype="xsd:string"></span><span id='am-7' property="oboInOwl:hasDbXref" content="KEGG:C00095" datatype="xsd:string"></span><span id='am-8' property="oboInOwl:id" content="IMR:0200474" datatype="xsd:string"></span><span id='am-9' property="rdfs:label" content="D-Fructose" datatype="xsd:string"></span>D-fructose</span>-6-phosphate product,                                                                        turn used substrate enzyme numbered <br /> Pairwise support vector machine <br />                                                                        EC 2.7.1.11. means enzyme-enzyme rela- rationale preceding discussion represent- <br />                                                                        tion EC 5.3.1.9 EC 2.7.1.11.  create <br /> ing disparate types data kernels enable                                                                        graph enzyme-enzyme relations edges <br /> use machine learning formalisms Support <br />                                                                        enzymes nodes shown Figure 2(b). Vector Machines (SVMs). SVMs used classifica- <br />                                                                        relation enzymes, relation clas- <br /> tion regression analysis, defined supervised models <br />                                                                        sified +1  e., interacting pair). Enzyme-enzyme pairs associated learning algorithms [33]. research, <br />                                                                        relation exists classified &#226;&#710;&#8217;1 (non- use SVMs classification. SVMs represents data <br />                                                                        interacting pairs). Figure 2(c) describes classifica- vectors vector space  e., input feature space). <br />                                                                        tions, used training set SVM method. training set, entities xi (vectors) classified categories given. SVM trained                Using pairwise kernel SVM predict metabolic <br /> hyperplane separates vector space parts.               networks feature space groups entities                input data, considered training example category.  new entity x classified              dataset ((xi , yi ), di ), set known pairs enzymes <br /> depending location feature space related            genes) classified categories (interacting hyperplane [33].                                                       non-interacting pairs). Figure 3  shows example   Pairwise Support Vector Machines, instead, classify pair             input data, obtained metabolic network entities (x, y) [32]. Let formally define binary             described Figure 2(c). Figure 3 , enzymes rep- <br /> Pairwise Support Vector Machine formulation, following                 resented EC number   gene nomenclature <br /> Brunner et al. [32]: given training data ((xi , yj ), di ),     . <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                                    Page 6 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />  Figure 2 Conversion metabolic network graph representation.   Glycolysis Pathways, BioCyc Database [5,6]. <br />  (b) resulting graph nodes (enzymes) edges (enzyme-enzyme relations). (c) Table represents known enzymes relations (EC <br />  numbers related classified +1 non-related -1). <br />  <br />  <br />   Figure 3(b) represents example pairwise                         Pairwise SVM based dual formalism kernel (K((x1 , y1 ), (x2 , y2 ))). state art pair-        optimization problem represented Figure 3(c). wise kernels mentioned  example,                     parameters &#206;&#177;ij b learned, using pairwise <br /> consider Tensor Product Pairwise Kernel K [22],                  kernel, K, training dataset, (xi , yi ). Finally, new <br /> K((x1 , y1 ), (x2 , y2 )) computed using simple kernel k             pairs enzymes genes (x, y) classified (e.g., k simple Phylogenetic (PFAM) ker-                     interacting interacting, depending evaluation <br /> nel described Ben-Hur et al. [22]). PFAM kernel                    decision function f  example representation <br /> (kpfam (x, y)) describes similarity measures based                 Figure 3(d)). predicting gene interactions PFAM database [34] gene x gene y.                     unseen examples, metabolic pathways  Tensor Product Pairwise Kernel K, using                    predicted. <br /> simple kernel PFAM Kernel kpfam defined                           pairwise kernel computation     K((x1 , y1 ), (x2 , y2 )) = kpfam (x1 , x2 ) &#226;&#710;&#8212; kpfam (y1 , y2 )       expensive tasks prediction metabolic <br />                                                                           networks processing storage. Using sequence data <br />                                 + kpfam (x1 , y2 ) &#226;&#710;&#8212; kpfam (y1 , x2 )     causes longer execution times large storage <br />   example, Figure 3(b)  genes                    needs.  mentioned advantages associated variables follow: x1 = YAR071W, y1 =                 using sequence data order avoid error accumu- <br /> YAL002W, x2 = YDR127W, y2 = YAL038W, Tensor                           lation genome annotation dependencies. Product Pairwise Kernel                                                 SVMs guarantee better accuracy values  <br />     K ((x1 , y1 ), (x2 , y2 )) = kpfam (YAR071W, YDR127W) &#226;&#710;&#8212; kpfam (YAL002W, YAL038W) <br />                  + kpfam (YAR071W, YAL038W) &#226;&#710;&#8212; kpfam (YAL002W, YDR127W) = 0.5. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                                              Page 7 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br />  Figure 3 Diagram pairwise SVM applied metabolic network prediction.   example pairs training set using EC <br />  numbers   gene names  . (b) pairwise kernel matrix, numerical values cell correspond measure  similarities, given pairs EC numbers   pairs gene names  . (c) model trained estimate parameters &#206;&#177;i,j b  decision function f . (d) Given new pair EC numbers (left) gene names (right) decision function evaluated pair classified  interacting non-interacting. <br />  <br />  <br />  <br />  <br /> supervised learning methods sequence ker-                              &#226;&#8364;&#162; Tensor Product Pairwise Rational Kernel <br /> nels metabolic network inference [7].                              (KPRKT ) focus improvement pairwise kernel computa-                                K((x1 , y1 ), (x2 , y2 )) = U(x1 , x2 ) &#226;&#710;&#8212; U(y1 , y2 )+ <br /> tions representation, incorporating rational kernels                         U(x1 , y2 ) &#226;&#710;&#8212; U(y1 , x2 ) manipulate sequence data. accomplish                            &#226;&#8364;&#162; Metric Learning Pairwise Rational Kernel proposed new framework called Pairwise Rational                              (KPRKM ) Kernels.                                                                            K((x1 , y1 ),(x2 , y2 )) = (U(x1 , x2 )&#226;&#710;&#8217;U(x1 , y2 )&#226;&#710;&#8217;U(y1 , x2 ) <br />                                                                                                               +U(y1 , y2 ))2 <br /> Methods                                                                           &#226;&#8364;&#162; Cartesian Pairwise Rational Kernel (KPRKC ) Pairwise rational kernels <br />                                                                                     K((x1 , y1 ), (x2 , y2 )) = U(x1 , x2 ) &#226;&#710;&#8212; &#206;&#180;(y1 = y2 ) section, propose new pairwise kernels based <br />                                                                                                                 +&#206;&#180;(x1 = x2 ) &#226;&#710;&#8212; U(y1 , y2 ) rational kernels, e., Pairwise Rational Kernels (PRKs). <br />                                                                                                                 +U(x1 , y2 ) &#226;&#710;&#8212; &#206;&#180;(y1 = x2 ) obtained using rational kernels sim- <br />                                                                                                                 +&#206;&#180;(x1 = y2 ) &#226;&#710;&#8212; U(y1 , x2 ) <br /> ple kernels k. defined PRKs, based                                                                                     &#206;&#180;(x = y) = 1 x = y 0  notations definitions Background Section <br />                                                                                     &#226;&#710;&#8364;x, y &#226;&#710;&#710; X.  <br /> Definition 1. Given X &#226;&#352;&#8224;   &#226;&#710;&#8212; transducer U,                            Following Theorem 1, construct U using function                                                                        weighted transducer T, U = T &#226;&#8212;&#166; T &#226;&#710;&#8217;1 , K : (X &#195;&#8212; X) &#195;&#8212; (X &#195;&#8212; X) &#226;&#8224;&#8217; R                                                    guarantee U Positive Definite Symmetric <br />                                                                                 (PDS) kernel. PDS needed condition use kernels <br />   &#226;&#8364;&#162; Direct Sum Pairwise Rational Kernel (KPRKDS )                          training classification algorithms. kernels <br />     K((x1 , y1 ), (x2 , y2 )) = U(x1 , x2 ) + U(y1 , y2 )+                      defined results PDS kernel operations,     U(y1 , x2 ) + U(x1 , y2 )                                                   PRK kernels PDS [35]. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                      Page 8 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Algorithm                                                          graph species. used SVM methods designed general algorithm, Algorithm 2,              metabolic network inference, prefer balanced <br /> compute kernels, using composition weighted             dataset. dataset, unbalanced pro- <br /> transducers. extension Algorithm 1.             portions interacting (+1) non-interacting (&#226;&#710;&#8217;1) <br /> uses input transducers Mx1 , My1 , Mx2 , My2 ,           classified pairs (e.g., dataset 282060 represent sequences x1 , y1 , x2 , y2 &#226;&#710;&#710; X         non-interacting pairs). order balance dataset, Weighted Finite-State Transducer U, outputs                followed procedure recommended Yu et al. [29], <br /> value K((x1 , y1 ), (x2 , y2 )).                                using program BRS-noint select non-interacting <br />                                                                    pairs. Yu et al. [29] describes bias non- <br /> Algorithm 2 Pairwise Rational Kernel Computation                   interacting pair selection training process                                                                    accuracy estimation. eliminate bias, BRS- <br /> INPUT: pairs sequences (x1 , y1 ), (x2 , y2 ) WFST U <br />                                                                    noint program used create &#226;&#8364;&#339;balanced&#226;&#8364;? negative <br />   obtain Mx1 , My1 , Mx2 , My2 use transducer <br />                                                                    set maintain right distribution non-interacting <br /> composition compute: <br />                                                                    interacting pairs. result, obtained 2574 non- <br /> N1 = Mx1 &#226;&#8212;&#166; U &#226;&#8212;&#166; Mx2 <br />                                                                    interacting pairs total 5149 pairs training <br /> N2 = Mx1 &#226;&#8212;&#166; U &#226;&#8212;&#166; My2 <br />                                                                    process. <br /> N3 = My1 &#226;&#8212;&#166; U &#226;&#8212;&#166; Mx2 <br /> N4 = My1 &#226;&#8212;&#166; U &#226;&#8212;&#166; My2 <br /> (ii) compute sum paths N1 , N2 , N3 , N4 using       Training process kernel computation <br /> shortest-distance algorithm                                        known metabolic network converted <br /> (iii) compute formulas Definition 1:                        graph obtained pairs training set, <br /> KPRKDS ((x1 , y1 ), (x2 , y2 )) = N1 + N2 + N3 + N4                corresponding Figure 3 . PRK representation <br /> KPRKT ((x1 , y1 ), (x2 , y2 )) = N1 &#226;&#710;&#8212; N4 + N2 &#226;&#710;&#8212; N3                 coincides Figure 3.  compu- <br /> KPRKM ((x1 , y1 ), (x2 , y2 )) = (N1 &#226;&#710;&#8217; N2 &#226;&#710;&#8217; N3 + N4 )2             tation PRKs  main contribution KPRKC ((x1 , y1 ), (x2 , y2 )) = N1 &#226;&#710;&#8212;&#206;&#180;(y1 = y2 )+N2 &#226;&#710;&#8212;&#206;&#180;(y1 = x2 )   research), given data yeast Saccharomyces <br /> +N3 &#226;&#710;&#8212; &#206;&#180;(x1 = y2 ) + N4 &#226;&#710;&#8212; &#206;&#180;(x1 = x2 )                               cerevisiae: <br /> RESULTS: values K((x1 , y1 ), (x2 , y2 )) <br />                                                                      &#226;&#8364;&#162; 755 known genes represented                                                                        trivial weighted automaton  e., Ax1 , Ax2 , . . . Ax755 ) <br />   implementation described  use n-                 using <span id='am-12' about='obo:IMR_0001349' typeof='owl:Thing obo:IMR_0001657 obo:IMR_0000947 obo:IMR_0000001 obo:IMR_0001698'><span id='am-13' property="rdfs:label" content="nucleoside phosphate" datatype="xsd:string"></span><span id='am-14' property="oboInOwl:hasDbXref" content="CHEBI:25608" datatype="xsd:string"></span><span id='am-15' property="obo:IAO_0000115" content="A nucleotide consists of a nitrogen-containing base, a five-carbon sugar, and one or more phosphate groups. Nucleotides can carry chemical energy (e.g. ATP), form coenzymes (e.g. CoA), be used as specific signaling molecules (e.g. cAMP) in the cell. Nucleotides are the subunits of the nucleic acids. " datatype="xsd:string"></span><span id='am-16' property="oboInOwl:hasExactSynonym" content="nucleoside phosphate" datatype="xsd:string"></span><span id='am-17' property="oboInOwl:id" content="IMR:0001349" datatype="xsd:string"></span><span id='am-18' property="rdfs:label" content="nucleotide" datatype="xsd:string"></span><span id='am-19' property="oboInOwl:hasOBONamespace" content="molecule_role" datatype="xsd:string"></span>nucleotide</span> sequences, <br /> gram rational kernel kernel U  n-gram kernel          &#226;&#8364;&#162; n-gram kernel, n = 3, used rational <br />                                                                                                           rational kernel Section details).               kernel, U(Ax1 , Ax2 ) =  =3 cAx1  cAx2    complexity steps   (ii) O(|Mx1 | + |My1 | +               n-gram kernel rational kernel Section |Mx2 | + |My2 |). Step (iii) adds constant time complexity.          details), conclude PRKs  based n-gram kernels              &#226;&#8364;&#162; Algorithm 2 implemented obtain K values, computed time O |Mx1 | + |My1 | + |Mx2 | + |My2 | .            &#226;&#8364;&#162; example, Tensor Product Pairwise Rational <br />                                                                        Kernel Definition 1 obtained  <br /> Experiments <br />                                                                        KPRKT ((x1 , y1 ), (x2 , y2 )) = section experiments predict <br /> metabolic networks using pairwise SVMs combined                   = U(Ax1 , Ax2 ) &#226;&#710;&#8212; U(Ay1 , Ay2 ) + U(Ax1 , Ay2 ) <br /> PRKs. aim prove advantage using PRKs                      +U(Ay1 , Ax2 ) <br />                                                                                                          <br /> improve execution time computation                   =  =3 cAx1  cAx2   &#226;&#710;&#8212;  =3 cAy1  cAy2  + <br />                                                                                                           <br /> pairwise kernels training process, maintain-                +  =3 cAx1  cAy2   &#226;&#710;&#8212;  =3 cAy1  cAx2  . <br /> ing improving accuracy values. <br />                                                                      &#226;&#8364;&#162; finally, PRK kernels K positive <br /> Dataset                                                                eigenvalues normalized avoid fact used data yeast Saccharomyces cerevisiae                   longer sequences contain n-grams, <br /> [36]. species selected compare methods,                resulting similarities [16]. <br /> implementations results methods predict biological networks Saccharomyces cerevisiae             implemented method compute PRKs <br /> [9,10,22].                                                         using Open Finite-State Transducer (OpenFST) library <br />   data species taken KEGG               [38] OpenKernel library [39]. input data pathway [37] converted graph described                 nucleotide sequences known genes, outputs previous section  Figure 2 details).           pairwise rational kernel values similarity 755 nodes 2575 interacting pairs             measure pairs. Example 3 shows input  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                     Page 9 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> output values method described  equivalent           represent abbreviated nucleotide sequences, inter- Figure 3(b), using sequence data.                           act interact. decision function, f (x, y),                                                                    previously obtained training process  Example 3. Given nucleotide sequences x1 , y1 , x2 , y2 ,          Pairwise support vector machine Section details). represent abbreviated examples known genes             resulting value evaluating decision function dataset,                                                       f (x, y) greater 0, pair (x, y) interact, x1 = GCTAAATTGGACAAATCTCAATGAAATTGTC                               pair (x, y) interact. Suppose evaluation <br /> TTGG                                                               y1 = ATGTCCTCGTCTTCGTCTACCGGGTACAGAA                               f (x, y) = f (CTCAAAGTCTTAATGCTTGGACAAATTGA <br /> AA                                                                 AATTGG . . . , TCTACAGAGTCGTCCTTCGTCTACCGG <br /> x2 = CATGACTAAAGAAACGATTCGGGTAGTTATT                               GAAAAT . . .) = +3. <br /> TGGCGG                                                              predict nucleotide sequences (x, y) <br /> y2 = ATCTACAAGCGAACCAGAGTCTTCTGCAGGC                               interact context metabolic network TTAGAT                                                             yeast Saccharomyces cerevisiae. Tensor Product Pairwise Rational Kernel KPRKT                  case, used 755 genes training pro- <br /> ((x1 , y1 ), (x2 , y2 )) obtained using 3-gram ratio-   cess, species 6000 genes [41]. <br /> nal kernel, e.g., = TCT, values                       rest metabolic pathways predicted <br />                                                                    classifying pairs genes  pairs raw <br />   &#226;&#8364;&#162; cAx   = 2  TCT appears twice x1                   nucelotide sequences), interacting non-interacting, <br />        1 <br />     GCTAAATTGGACAAATCT CAATGAAATTG                                 using decision function f . Note decision func- <br />     TCT TGG,                                                       tion obtained training process,   &#226;&#8364;&#162; cAy   = 2  TCT appears twice y1                   used needed prediction process. <br />        1 <br />     ATGTCCTCGTCT TCGTCT ACCGGGTACAGA <br />     AAA,                                                             advantage using sequence data nucleotide <br />   &#226;&#8364;&#162; cAx   = 1  TCT appears x2                    sequences used, annotated. <br />        2 <br />     CATGACTAAAGAAACGATTCT GGTAGTTATT                                type sequence data, e.g., high- <br />     TGGCGG,                                                    throughput analysis, considered combined, <br />   &#226;&#8364;&#162; cAy   = 3  TCT appears times y2             using similar implementation. <br />        2 <br />     ATCT ACAAGCGAACCAGAGTCT TTCT GCAGG <br />     CTTAGAT.                                                       Experiment description performance measures <br />                                                                    used pairwise SVM PRKs metabolic <br />   results values corresponding                network prediction, using data algo- 3-gram rational kernel, KPRKT computed                rithms described  ran experiments KPRKT ((x1 , y1 ), (x2 , y2 )) = 0.3, 0.3 measure    different kernels. Firstly, used PRKs <br /> similarity.                                                        described Definition 1 using 3-gram rational <br />                                                                    kernel  e., KPRKDS&#226;&#710;&#8217;3gram , KPRKT&#226;&#710;&#8217;3gram , KPRKM&#226;&#710;&#8217;3gram <br /> SVM predicting process                                         KPRKC&#226;&#710;&#8217;3gram ). addition, combination PRKs implement pairwise SVM method, use                   kernels considered. included sequential minimal optimization (SMO) technique               phylogenetic kernel (Kphy ) described Yamanishi 2010 package LIBSVM [40] combination OpenKer-               [9] PFAM kernel (Kpfam ) Ben-Hur et al. <br /> nel library [39]. training process, decision        [22].  second set experiments devel- <br /> function obtained estimating parameters,          oped combining PRKs phylogenetic kernel  e., <br /> shown Figure 3(c).  prediction process allows           KPRKDS&#226;&#710;&#8217;3gram + Kphy , KPRKT&#226;&#710;&#8217;3gram + Kphy , KPRKM&#226;&#710;&#8217;3gram + <br /> classification new pairs nucleotide sequences             Kphy KPRKC&#226;&#710;&#8217;3gram + Kphy ). Finally, combined <br /> interacting interacting evaluating decision          PRKs PFAM kernel, obtaining KPRKDS&#226;&#710;&#8217;3gram + <br /> function. Example 4 shows description prediction          Kpfam , KPRKT&#226;&#710;&#8217;3gram + Kpfam , KPRKM&#226;&#710;&#8217;3gram + Kpfam process, similar process described Figure 3(d),          KPRKC&#226;&#710;&#8217;3gram + Kpfam kernels. Considering phy- using nucleotide sequences.                                    logenetic PFAM kernels PDS, resulting <br />                                                                    combinations PDS [35]. <br /> Example 4. example predictor process.              compare advantages PRKs framework, <br /> Suppose want know                                         developed new set experiments x = CTCAAAGTCTTAATGCTTGGACAAATTGAAAT                               dataset, using finite-state transducers. TGG,                                                           considered pairwise (n-gram) kernel, e., KT&#226;&#710;&#8217;3gram . <br /> y=TCTACAGAGTCGTCCTTCGTCTACCGGGAAAAT,                               KT&#226;&#710;&#8217;3gram denoted pairwise tensor product described <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                          Page 10 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  Pairwise kernels Section. consistent                accuracy comparable Experiments II III. <br /> previous experiments, combined KT&#226;&#710;&#8217;3gram ker-                       Similar results obtained Yu et al. [29] PPI net- <br /> nel phylogenetic kernel (Kphy ) PFAM kernel                  works. stated simple sequence-based kernels, (Kpfam ), e., KT&#226;&#710;&#8217;3gram + Kphy KT&#226;&#710;&#8217;3gram + Kpfam ker-                 n-gram, properly predict-protein interactions. <br /> nels, respectively. pairwise SVM algorithm used                    Yu et al. [29] combined sequence kernels predict metabolic network using data set                  kernels incorporate evolutionary informa- <br /> described  Table 1 describes groups created                  tion, accuracy model predictor improved. <br /> compare kernels equivalent PRKs.                           obtained similar results applied metabolic net- <br />    experiments executed PC intel                        works predictions: PHY PFAM kernels i7CORE, 8MB RAM. validate model, used                       included (Experiments II III, respectively), accuracies <br /> 10-fold cross validation method measured average                  improved maintaining adequate processing <br /> Area Curve Receiver Operating Characteris-                   times. best accuracy value obtained com- <br /> tic (AUC ROC) score.                                                      bining PRK-Metric-3gram PFAM kernels (aver- <br />    Cross-validation method suitable approach val-                 age AUC=0.844). papers used similar kernel <br /> idate performance predictive models. k-fold cross-                  combinations improve prediction biological net- <br /> validation, original dataset randomly partitioned                  works, Ben-Hur et al. [22] Yamanishi [9]. k equal-sized subsets.  model trained k                   rational kernels used previous <br /> times. time, k subsets reserved                    research. <br /> testing remaining k &#226;&#710;&#8217; 1 subsets used                    Ben-Hur et al. [22] report average AUC value training. final value obtained average k             0.78 PFAM kernels, Yamanishi [9] reports results  Kohavi et al. [42] details).                        average AUC 0.77 PHY kernel predicting <br />    Receiver Operating Characteristic (ROC) curve                   Saccharomyces cerevisiae metabolic pathways. plot True Positive Rate (TPR) versus False Pos-                previously developed similar experiments using SVM <br /> itive Rate (FPR) different possible cut-offs binary              methods [7]. result, obtain AUC values 0.92 <br /> classifier  cut defines level discriminat-             PFAM kernel 0.80 PHY kernel, execution <br /> ing positive negative categories. ROC curve analysis                  times 12060 7980 seconds, respectively.  used assess overall discriminatory ability               cases random selection negative posi- <br /> SVM binary classifiers. area curve (aver-                   tive training data used. noted Yu et al. [29], <br /> age AUC score) used metric evaluate                  average AUC values obtained random selection strength classification.                                           data training machine learning tools results bias <br />    addition, 95% Confidence Intervals (CIs)                        genes  proteins) large numbers inter- computed, following method described                        actions.  high AUC results previous Cortes Mohri [43]. authors provide                           works directly compared results distribution-independent technique compute confi-                      paper. employed balanced sampling tech- <br /> dence intervals average AUC values. variance                      niques suggested Yu et al. [29] combat bias depends number positive negative examples                     training set. results, average AUC values (2575 2574 cases) number classifica-                range 0.5-0.844, comparable exceed cases tion errors, ranging 889 1912 cases.                   results obtained Yu et al. [29] balanced sampling, <br />                                                                           range 0.5-0.75 different kernels <br /> Results discussion                                                    protein interaction problems. obtained <br /> Table 2 shows SVM performance, execution times                    results execution times 15-140 seconds. 95% CIs grouped kernels mentioned                      exception direct sum kernel,   experiments using PRK best                 fidence intervals behaviour random <br /> execution times (Exp.  transducer representations                classifier. algorithms speed processing.                         developed experiment PFAM <br />                                                                           kernel simple kernel Pairwise Tensor Product <br /> Table 1 Groups PRK pairwise kernel comparison                     (Kpfam ) using balanced sampling suggested Yu <br />                                                                           et al. [29]. Note PRK; regular <br /> Group             PRKs 1                              Pairwise Kernel 2 <br />                                                                           pairwise kernel using PFAM simple kernel, similar <br /> N-GRAM            KPRKT&#226;&#710;&#8217;3gram                         KT&#226;&#710;&#8217;3gram            example Using pairwise kernel SVM <br /> PHY               KPRKT&#226;&#710;&#8217;3gram +Kphy                   KT&#226;&#710;&#8217;3gram + Kphy     predict metabolic networks Section. result, PFAM              KPRKT&#226;&#710;&#8217;3gram +Kpfam                  KT&#226;&#710;&#8217;3gram + Kpfam    average AUC 0.61 execution time 122 <br /> 1 <br />   Kernels taken Table 2. <br />                                                                           seconds. compare values results <br /> 2 <br />   Computed Tensor Product Pairwise Kernel.                       Table 2 Exp.  kernels KPRKM&#226;&#710;&#8217;3gram <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                           Page 11 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  <br /> Table 2 Average AUC ROC scores processing times various PRKs <br /> Exp        Type kernels      Kernel                                         Average AUC score   Runtime (sec)    Confidence intervals <br />            Pairwise Rational    PRK-Direct-Sum (KPRKDS&#226;&#710;&#8217;3gram )                 0.499               15.0             [0.486, 0.512] <br />            Kernels (PRK)        PRK-Tensor-Product (KPRKT&#226;&#710;&#8217;3gram )              0.597               16.2             [0.589, 0.605]            (3-gram)             PRK-Metric-Learning (KPRKM&#226;&#710;&#8217;3gram )             0.641               17.4             [0.633, 0.648] <br />                                 PRK-Cartesian (KPRKC&#226;&#710;&#8217;3gram )                   0.640               15.0             [0.632, 0.647] <br />            PRKs combined        PRK-Direct-Sum+Phy (KPRKDS&#226;&#710;&#8217;3gram + Kphy )      0.425               136.2            [0.411, 0.438] <br />            phylogenetic    PRK-Tensor+Phy (KPRKT&#226;&#710;&#8217;3gram +Kphy )            0.733               135.6            [0.725, 0.741] <br /> II <br />            data (Kphy Non-      PRK-Metric+Phy (KPRKM&#226;&#710;&#8217;3gram +Kphy )            0.761               139.2            [0.753, 0.768] <br />            sequence kernel)     PRK-Cartesian+Phy (KPRKC&#226;&#710;&#8217;3gram +Kphy )         0.742               132.6            [0.734, 0.749] <br />            PRKs combined        PRK-D-Sum+PFAM (KPRKDS&#226;&#710;&#8217;3gram +Kpfam )          0.493               136.2            [0.480, 0.506] <br />            PFAM data       PRK-Tensor+PFAM (KPRKT&#226;&#710;&#8217;3gram +Kpfam )          0.827               136.8            [0.819, 0.834] <br /> III <br />            (Kpfam               PRK-Metric+PFAM (KPRKM&#226;&#710;&#8217;3gram +Kpfam )          0.844               140.4            [0.837, 0.850] <br />            Sequence kernel)     PRK-Cartesian+PFAM (KPRKC&#226;&#710;&#8217;3gram +Kpfam )       0.842               132.0            [0.835, 0.849] <br />  <br />  <br />  KPRKC&#226;&#710;&#8217;3gram better average accuracy  e., 0.641                   classification methods. McNemar&#226;&#8364;&#8482;s test defines 0.640, respectively) lesser average execution                      score, calculated  <br /> times (17.4 15.0 seconds, respectively). addition,                                                 <br />                                                                                        |Nsf &#226;&#710;&#8217; Nfs | &#226;&#710;&#8217; 1 Pairwise Rational Kernel 3-gram combined                           =                                              (2) <br />                                                                                                        PFAM kernel Exp. III,  e., Tensor                                        Nsf + Nfs <br /> Product Pairwise Rational Kernel - KPRKT&#226;&#710;&#8217;3gram +Kpfam ), average accuracy value (average AUC=0.827)                          Nfs number times Algorithm failed <br /> better Pairwise Tensor Product (Kpfam ),                     Algorithm B succeeded, Nsf number execution time just increased 14.8 seconds  e.,                   times Algorithm succeeded Algorithm B failed. 122 seconds, using Kpfam , 134.8 seconds, using                     equal 0, algorithms similar <br /> KPRKT&#226;&#710;&#8217;3gram +Kpfam ).                                                       performance. Additionally, Nfs larger Nsf   order statistically compares theses results,                     Algorithm B performs better Algorithm  vice <br /> applied McNemar&#226;&#8364;&#8482;s non-parametric statistical test                       versa. computed scores considering Algorithm [44]. McNemar&#226;&#8364;&#8482;s tests recently used Bostanci                   SVM algorithm using Pairwise Tensor Product <br /> et al. [45] prove significant statistical differences                    (Kpfam ) different Algorithm Bs, using SVM <br />  <br />  <br />  <br />  <br />      Figure 4 Comparison pairwise rational kernels pairwise kernels grouped kernel types (N-GRAM group, PHY group      PFAM group). <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                             Page 12 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br />  <br />  <br />  different PRKs Table 2  e., KPRKM&#226;&#710;&#8217;3gram ,   used similar types stochiometric data, KPRKC&#226;&#710;&#8217;3gram KPRKT&#226;&#710;&#8217;3gram +Kpfam mentioned .          converted kernels consider PRKs. cases, obtained scores greater 0  e., <br /> 4.73, 4.54, 7.51), mean PRKs performed better.      Conclusion score proved difference statis-     paper, introduced new framework called <br /> tically significant confidence level 99% (based     Pairwise Rational Kernels, pairwise kernels tailed Prediction Confidence Levels described          obtained based transducer representations, e., ratio- [45]).                                                     nal kernels. defined framework, developed general <br />    Cartesian Kernel widely used        algorithms tested pairwise Support Vector defined Kashima et al. [10]. Kashima et al. [10]    Machine method predict metabolic networks. <br /> used Expression, Localization, <span id='am-1' about='obo:IMR_0000947' typeof='owl:Thing obo:IMR_0000001'><span id='am-2' property="oboInOwl:hasOBONamespace" content="molecule_role" datatype="xsd:string"></span><span id='am-3' property="oboInOwl:id" content="IMR:0000947" datatype="xsd:string"></span><span id='am-4' property="rdfs:label" content="chemical" datatype="xsd:string"></span>Chemical</span> Phylogenetic        used dataset yeast Saccharomyces cere- <br /> kernels predict metabolic networks.          visiae validate compare proposal similar non-sequence kernels. current experiments          models using data species. obtained computed, time, pairwise Cartesian ker-      better execution times models, nel rational kernel (sequence kernel) repre-        maintaining adequate accuracy values.  PRKs <br /> sent sequence data metabolic network prediction.          improved performance pairwise-SVM algo- <br /> Cartesian kernels [10] defined alternative    rithm used training process supervised improve Tensor Product Pairwise Kernel [22] com-       network inference methods. <br /> putation performance. experiments shown         methods, learning process executed <br /> Table 2, confirmed definition, obtained    obtain decision function. decision func- <br /> better accuracy execution times used          tion used times necessary predict <br /> Cartesian Pairwise Rational Kernel (KPRKC&#226;&#710;&#8217;3gram )      interaction sequences species Tensor Product Rational Kernel (KPRKT&#226;&#710;&#8217;3gram ).       predict metabolic pathways. <br /> Comparing results Kashima et al. [10],              methods research used sequence data <br /> obtained better average AUC values  e., 0.844 vs 0.79),     (e.g., nucleotide sequences) predict interactions. approximately average execution           Genes need correctly annotated raw <br /> times  e., 93 seconds). Kashima et al. [10] used non-       sequences used.  methods sequence data random selection positive nega-      able avoid error accumulation wrong gene <br /> tive data training.                                       annotations. <br />    Figure 4 shows results experiments compar-        future work, proposal used produce ing PRK framework pairwise kernels.        set candidate interactions pathways comparative groups described Table 1 used.      species, experimentally validated. seen, execution times better       pairwise rational kernels developed <br /> PRKs used groups. proves PRKs      using finite-state transducers operations. <br /> compute faster rational kernels use finite-state <br /> transducer operations representations, improving      Competing interests <br />                                                               authors declare competing interests. <br /> performance. <br />    power using kernels sort         Authors&#226;&#8364;&#8482; contributions data represented using kernels.           ARL implemented algorithms developed experiments. ARL, MD <br />                                                               BF contributed equally drafting manuscript. authors completely disparate types data combined         reviewed approved final version manuscript. <br /> add power kernel-based machine learning methods <br /> [8]. example, coefficients describing relative amounts    Acknowledgements <br />                                                               work funded Natural Sciences Engineering Research Council of metabolites involved biochemical reaction  e.,      Canada (NSERC) Microbial Genomics Biofuels Products stochiometric data) represented ker-           Biorefining Processes (MGCB2 project). <br /> nels added strength predicting model. example, reaction catalyzed fructose-bisphosphate      Author details <br />                                                               1 Department Science, University Manitoba, Winnipeg, <br /> aldolase [EC 4.1.2.13] splits 1 molecule fructose          Manitoba, Canada. 2 Department Plant Science, University Manitoba, R3T <br /> 1,6-bisphosphate 2 molecules glyceraldehyde           2N2 Winnipeg, Manitoba, Canada. <br /> 3-phosphate, relative amounts substrate <br />                                                               Received: 11 April 2014 Accepted: 23 September 2014 product represented coefficients 1         Published: 26 September 2014 <br /> 2, respectively. stoichiometric kernel encode coefficients substrates products,    References <br />                                                               1. Faust K, Helden J: Predicting metabolic pathways sub-network <br /> enzymes interact stoichiometric            extraction. Bacterial Molecular Networks. Methods Molecular Biology. <br /> coefficients 0. authors [46-48] defined         Springer: New York; 2012:107&#226;&#8364;&#8220;130. <br />  Roche-Lima et al. BMC Bioinformatics 2014, 15:318                                                                                                   Page 13 13 <br /> http://www.biomedcentral.com/1471-2105/15/318 <br />  <br /> </body></html>